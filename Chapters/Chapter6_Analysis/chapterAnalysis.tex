\chapter{Measurement of anomalous couplings in top-quark decays} \label{ch::Analysis}

\textit{With all necessary objects and methods clearly established in the previous chapters, the focus can now finally shift towards the actual topic of this thesis./the actual measurement performed in this thesis.}
The goal of the performed/this measurement, of which all aspects will be rigorously discussed in this chapter, is to determine the right-handed tensor coupling of the Wtb interaction vertex using a Matrix Element method.
\\

However, before the actual measurement can be done, additional research is still required in order to ensure that the procedure developed to extract the result/minimum from the Matrix Element method is behaving properly. This because such a method can be negatively influenced by the applied model approximations, a \textit{condition/ option/ possibility/ property} that should be tested using a \textit{linearity test/bias determination} for which the details can be found in Section~\ref{sec::CalibCurve}.
Afterwards some specific characteristics of the performed analysis will be discussed in Section~\ref{sec::RecoAdapt}.
Main focus here will lie/be on understanding the challenges associated with applying a Matrix Element method on reconstructed collision events.
Once the entire framework required to investigate these type of events is established, the actual measurement will be discussed in Section~\ref{sec::Meas}. 
%\textit{Also an overview of the relevant systematic uncertainties will be given here.}

\section{Linearity test of the Matrix Element method} \label{sec::CalibCurve}
%--> Maybe even get a stronger title ...

In order to ensure neither the constructed model nor the developed minimisation procedure hampers the applicability of the Matrix Element method, a detailed \textit{linearity test} will be performed.
This because the complexity of this method necessitates the introduction of some model approximations, all of which have the potential to influence the obtained result in a significant manner.
In addition, the technique used to extract the relevant information from the likelihood retrieved from the Matrix Element method can also (possibly) bias the outcome.
\\
\\
The \textit{calibration procedure} will determine whether for the different coupling coefficients any deviation from the expectation is observed.
Hence, various samples created with alternative coupling coefficients are needed for which the retrieved minimum should correspond to the value used to create them. Any deviation between the two would indicate the Matrix Element method has been affected with a bias, for which should be corrected for afterwards.
%*************************
% Interesting to mention such a statement already here ??
% --> First stick to the generator-level result and the testing of the method, and only then discuss the reco results!
%*************************
\\

Obtaining samples of reconstructed collision events with alternative coupling coefficients is not a trivial task, especially when compared to the ease with which generator-level events can be created.
%One of the more difficult aspects of this \textit{linearity test} is obtaining samples of reconstructed collision events generated with alternative coupling coefficients, this in contrast to the ease with which generator-level events can be created. 
Therefore, it has been opted for in this thesis to perform this \textit{linearity test} with the latter type of events.
However, since the event-selection is one of the more likely candidates to expect a different effect depending on the considered coupling coefficient, the generated events will have to fullfill some basic selection requirements.
\\
These event-selection criteria, which have been summarised in Table~\ref{table::GenCuts}, are chosen to be in close agreement with the kinematic constraints applied in the full event-selection chain discussed in Chapter~\ref{ch::EvtSel}. Unfortunately the identification and additional fine-tuning criteria cannot be taken into account, but are on the other hand not expected to be as dependent on the value of the coupling coefficient.
\begin{table}[h!t]
 \centering
 \caption{Basic event selection applied to the generator-level events in order to partially mimic the situation existing for the reconstructed collision events.} \label{table::GenCuts}
 \renewcommand{\arraystretch}{1.2}
 \begin{tabular}{c|c|c|c}
  Particle 	& $\pT$-cut 		& $\vert \eta \vert$-cut 	& $\Delta$R-cut 	\\
  \hline
  Jets 		& $>$ 30 $\GeV$ 	& $<$ 2.5			& $<$ 0.3		\\
  Muon		& $>$ 26 $\GeV$		& $<$ 2.1			& $<$ 0.3		\\
  Neutrino 	& $>$ 25 $\GeV$		& $<$ 2.5			& $<$ 0.3		
 \end{tabular}
\end{table}

The generator-level samples used for this linearity test have been created with the MadGraph event generator and contain \textcolor{red}{20 000} events, a value comparable in size to the number of selected data events. 
Since the considered right-handed tensor coupling, $\gR$, is supposed to be equal to $0$ in the Standard Model, the linearity test has been restricted to the range $\left[-0.15, 0.15\right]$.
This because the minimum-extraction procedure has proven to give rise to sufficiently accurate/precise results such that, in case any bias would exist, it has to be recovered within this limited range.
%Question: Mention that this decision was also driven by the fact that the fit is not accurate enough because there is not enough bin-information outside this range??
\\
\\
Each generated sample has been analysed by the Matrix Element method and its minimum has been determined using exactly the same method as will be applied for the reconstructed collision events.
The obtained minimum is then compared to the expected value of the corresponding sample, which should correspond to the coefficient imposed during the generation process.
In order to ensure both the model and method are not biased, the overall shape of the obtained results should be consistent with a straight line through the origin with a slope of $1$.
\\
%\textit{This resemblance is indeed recovered, as can be seen in Figure~\ref{fig::CalibCurve}, for which the relevant parameters are given in Equation (\ref{eq::CalibCurveResults}).}
%\begin{equation} \label{eq::CalibCurveResults}
% \textrm{slope} = xxx \pm xxx \qquad \& \qquad \textrm{off-set} = xxx \pm xxx  
%\end{equation}

For this analysis an almost perfect match has been recovered, as can be seen from Figure~\ref{fig::CalibCurve}. 
This agreement is confirmed when the obtained shape of the linearity test is compared with the expected one, resulting in a $\chi^{2}$-value of $xxx \pm xxx$ such that can be concluded that both distributions are statistically compatible. Hence, the measurements obtained with the introduced model can be trusted and no calibration should be applied to the final result.
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/CalibrationCurve_SlopeComparision_DifferentCuts.pdf}
 \caption{Outcome of the linearity test for the created model, indicating the absence of a bias due to the assumed model approximations. The calibration is therefore described perfectly since it can be represented by a straight line with slope $1$.} \label{fig::CalibCurve}
\end{figure}
%********************************
%Question: Fit also done by excluding the outer bins?
%********************************
%
%From the performed linearity test is clearly visible that the introduced model (and method) do not result in a bias.
%However, in order to reinforce this statement/conclusion, a chi-sq test has been carried out.
%\\
%Since the performed linearity proves that the introduced model does not result in a bias and thus the measurements obtained with the discussed model can be trusted, no calibration will be applied to the obtained outcome. The small deviation from the expected curve is perfectly covered by the corresponding uncertainty (\textbf{Check if this is also the case for the intersect value}) and should thus not be taken into account.
%\\
%
%\textbf{Statistically compatible with a straight line --> do a chi-sq test!}
%
%This means that the linearity test to check whether the model approximations might have introduced a bias has to be performed using the generator-level results and afterwards the entire curve needs to be shifted to the correspond with the result obtained from the signal $\ttbar$ sample.

\section{Required MEM framework adaptations} \label{sec::RecoAdapt}
%**********************
% Can also just make the section about the event cleaning but give this XS calculation as an introduction!
%  --> Work with paragraphs maybe ? (not so interesting to use paragrapsh in section ...)
%**********************

%First of all, the cross-section for these type of events for all the considered coupling coefficients should be determined, which is not as straightforward as was the case for the generator-level events discussed in the previous chapter. The approach opted for in this thesis will be discussed in Section~\ref{sec::RecoAdapt}.
%The second characteristic to be discussed here focusses on the adaptations necessary to have the Matrix Element method correctly deal with reconstructed events. 
%The fact that these events are more prone to detector inefficiencies or misdetermined kinematics significantly complicates the calculations.

An important aspect of the Matrix Element method is the normalisation of the event probability using the cross-section and acceptance, which might vary significantly for the considered configurations. For the top-quark mass example given in Section~\ref{sec::TopMass}, the effect of this normalisation was negligible but for the measurement of the anomalous coupling coefficient this factor has proven to be rather important. The method opted for in this analysis to determine these cross-section values will be explained in Section~\ref{subsec::XSReco}.
%*********************************
% --> Check if this XS is actually important for the top-mass ..
%*********************************
\\

Another essential/vital feature that should be investigated thoroughly is the less optimal behaviour of the Matrix Element method when considering reconstructed collision events.
This because these type of events are more likely to be affected by detector inefficiencies, ill-defined kinematic variables and wrongly reconstructed event topologies.
%Analysing reconstructed collision events using a Matrix Element method deviates significantly from any generator-level study, mainly because the former type of events tend to be influenced by detector inefficiencies, ill-defined kinematic variables or wrongly reconstructed event topologies.
Since the Matrix Element method will treat all events as if they were real semi-leptonic top-quark pair decays, any inconsistency from the expected topology is likely to result in the underlying mathematical framework to misdetermine the event probability.
Therefore it is of crucial importance a procedure is developed in order to exclude the contribution of these sort of events, for which the details will be given in Section~\ref{subsec::EvtCleaning}.

%In order to correctly apply the Matrix Element method on reconstructed collision events, a different approach than the one used for generator-level events is required.
%At first, the ease \textbf{with which} generator-level samples with an alternative mass or coupling (\textit{Check whether any example of couplings is given ...}) could be created can not be repeated for these reconstructed events. Therefore, the linearity test performed to test the validity of the considered model assumptions will be performed using generator-level events, as explained in Section~\ref{subsec::CalibCurve}. Also the cross-section values at non-SM coupling coefficients for the reconstructed events need to be extrapolated from these generator-level events, a procedure which will be discussed in Section~\ref{subsec::XSReco}.
%\\
%Secondly, and more related to the actual application of the technique, the possible influence of detector inefficiencies, ill-defined kinematic variables or wrongly reconstructed event topologies has a detrimental effect on the calculation of the event probability. 
%Therefore an additional event cleaning procedure, outlined in detail in Section~\ref{subsec::EvtCleaning}, is required in order to limit the importance of these type of events. 

\subsection{Determining the cross-section for reconstructed events} \label{subsec::XSReco}

For the measurement of the right-handed tensor coupling the cross-section normalisation is a vital component.
Independent whether generator-level or reconstructed events are considered, without this normalisation applied the Matrix Element method does not result in the correct outcome.
The substantial influence of this normalisation component has been summarised in Figure~\ref{fig::XSInflGen}, which shows the overall $\chiSqMEM$ distribution prior to and after the cross-section normalisation has been taken into account. The considered sample has been created using the Standard Model configuration such that the minimum of the distribution should correspond to $0$.
%This because the observed variations of the overall event probability for the coupling coefficient are much smaller than was the case for the top-quark mass measurement such that the cross-section normalisation actually has a significant influence on the obtained outcome.
%***********************************
% --> Certain this is the reason?
% ==> Maybe good to think of an explanation why this cross-section normalisation is so much more important
%***********************************
\begin{figure}[h!t]
 \centering
 % Add here the gR gen-level result of FitDistributions_CalibCurve_SemiMu_RgR_AllDeltaTF_MGSampleSM_20000Evts_NoCuts_OuterBinsExclForFit_20000Evts.root with and without XS normalisation
 % Important: Cannot yet use the sample after the event-selection is applied because this still has to be explained!!
 % --> Do this without the fit maybe .. ?
 \includegraphics[width = 0.3 \textwidth]{image.png} \hspace{0.5cm}
 \includegraphics[width = 0.3 \textwidth]{image.png}
 \caption{Distribution of the overall $\chiSqMEM$-value obtained by analysing the right-handed tensor coupling using 20 000 generator-level events. The distribution on the left is without any normalisation applied while the right one corresponds to the normalised result.} \label{fig::XSInflGen}
\end{figure}

The significant impact of the cross-section normalisation on the outcome of the measurement implies that the cross-section values for the reconstructed-level analysis should be determined with great care.
However, in contrast to the easy access to generator-level samples with alternative coupling coefficients, generating similar samples containing reconstructed events is a rather challenging and time-consuming process.
As a result, it has been opted for in this thesis to derive the cross-section values for the reconstructed events from the generator-level ones.
This approach significantly facilitates the cross-section determination since any generated process by MadGraph automatically calculates the cross-section of the considered process.
%**********************
% Any other motivation why FastSim has not been considered?
% --> Certain that it would perfectly describe the SM samples??
%**********************
\\
\\
In order to ensure that the obtained generator-level cross-sections can easily be related to the reconstructed ones, the conditions present for the reconstructed collision events will be mimicked as closely as possible during the generation process. Hence the generator events have to fullfill the basic event selection requirements\footnote{Important to note here is that once these selection criteria are applied to the generated events, the obtained cross-section will actually be a combination of the cross-section of the underlying physics process and the acceptance of the considered event selection. Hence the term ``cross-section normalisation'' will \textbf{implicitely} imply the combined normalisation $\sigma \times A$ mentioned in Equation~\ref{eq::MWEvtProb}.} listed in Table~\ref{table::GenCuts}.
By applying a significant fraction of the full event selection chain onto the generated events, the expected relative difference in behaviour of each $\gR$ value on the considered kinematic constraints will be incorporated. As previously mentioned in Section~\ref{sec::CalibCurve}, the remaining event-selection criteria are supposed to be less sensitive to the value of the coupling coefficient.
%The remaining event selection criteria are believed to be less sensitive to the value of the coupling coefficient, thus their relative dependence will not be taken into account.
\\
\\
In addition, the generated processes are also selected in order to remain with a similar event signature as is the case in data. Hence the cross-section values have been determined using a combination of top-quark pair decay processes surrounded with additional jets. The actual number of considered processes has been limited to the $\ttbar$ decay with none, one and two additional jets since the contribution of the following decays quickly becomes negligible.
%********************************************
% --> Does this correspond to LO, NLO and NNLO or is this still something different??
% Question: Interesting to give some of the Feynman diagrams belonging to the different processes?
%********************************************
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.15 \textwidth]{image.png} \hspace{0.2cm}
 \includegraphics[width = 0.15 \textwidth]{image.png} \hspace{0.2cm}
 \includegraphics[width = 0.15 \textwidth]{image.png}
 \caption{Feynman diagrams for the different generator-level processes considered for the calculation of the cross-sections. \textbf{Relevant?}}
\end{figure}

Even with these two optimisations applied, this approach will not result in a perfect agreement with the selected events. For instance, it is simply not possible to include every aspect of the full event-selection chain in exactly the same way when generating the different processes.
Hence, the obtained cross-section values will be scaled in order to take into account the influence of these non-included event selection criteria.
For this an identical behaviour throughout the entire $\gR$ range is assumed such that each cross-section value will be multiplied with the factor $\sigma_{SM}^{reco}$/$\sigma_{SM}^{gen}$. 
%********************************************
% --> Think of any other non-included effects!!
%********************************************
\\
In this factor the term $\sigma_{SM}^{reco}$ represents the measured cross-section of the selected events while the cross-section obtained for the combined generator-level sample created using the Standard Model configuration is denoted by $\sigma_{SM}^{gen}$.
The cross-section of the selected events is determined by dividing the semi-leptonic $\ttbar$ event count obtained after the full event selection chain with the luminosity of this sample, which has been given previously in Table~\ref{table::Samples}. 
\\

The final result of the cross-section calculation can be found in Figure~\ref{fig::XSDistr}, which shows the distribution of the cross-section values obtained for the generator-level events using the approach discussed above. The cross-section values for the selected events are also given in this Figure, obtained by multiplying each of the former cross-sections with the fixed scaling factor $\sigma_{SM}^{reco}$/$\sigma_{SM}^{gen}$ = $0.326$. \textbf{Recalculate!}
\\
\textbf{Remark: Used luminosity and number of events do not seem to be correct!}
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/XSDistributions.pdf}
 \caption{Overview of the distribution of the generator-level cross-sections for different $\gR$ values and the reconstructed ones derived from them by applying the ratio $\sigma_{SM}^{reco}$/$\sigma_{SM}^{gen}$.} \label{fig::XSDistr}
\end{figure}

%--------------------------------------------------------------------------------------------------------- \\
%Also here there is an additional complexity when considering reconstructed events, since the cross-section of the $\ttbar$ decay depends on the value of the coupling coefficients in the interaction vertex. For generator-level events, these values are accesible for each generated sample since MadGraph automatically determines the cross-section of each generated process.
%\\
%Hence the cross-sections for these reconstructed events are derived from the MadGraph predictions by carefully calculating the generator-level cross-sections in a regime comparable to data. 
%This condition has been achieved by combining the cross-sections for each $\gR$ coefficients when no, one and two additional jets are included in the event. 
%This will not result in a perfect match to data, but will bring the considered configuration a bit closer to reality. 
%\\
%Since the cross-section should be include the effect of the event selection, the different MadGraph samples have to fullfill the different kinematic requirements given in Table~\ref{table::GenCuts}. The three different contributions are then added in order to obtain an overall cross-section for the \textbf{inclusive} 2-jet case, for which the results have been summarised in the second column of Table~\ref{table::XSValues}.
%The third column contains the cross-section values that will be applied for the measurement using the reconstructed events, and have been obtained by scaling the cross-section for each $\gR$ value with the fraction $\sigma_{SM}^{reco}$/$\sigma_{SM}^{gen}$. This ratio corrects the generator-level cross-sections to the expected reco-level one and can be applied onto all $\gR$ configurations since the relative effect of the event selection is already been incorporated by applying the basic event selection requirements on the MadGraph samples. The value $\sigma_{SM}^{reco}$ has been determined by dividing the number of selected events with the total number of events present in the sample and multiplying this with the cross-section of the semi-leptonic $\ttbar$ sample, which thus corresponds to multiplying the selected number of events with the luminosity of the simulated sample. The distribution of the generator-level cross-sections and the reconstructed ones is given in Figure~\ref{fig::XSDistr} and serves as an easy way to determine the reconstructed cross-section for other $\gR$ values if required.
%
%\begin{table}[h!t]
%  \centering
%  \caption{Overview of the cross-section values used for the reconstructed events together with the inclusive $\ttbar$+2jet events from which they have been derived. \textbf{Maybe redundant if figure is %given ..}} \label{table::XSValues}
%  \small
%  %\begin{tabular}{|c||c|c|c|c||c|}
%  \begin{tabular}{|c|c|c|}
%   \hline
%%   $\gR$ coefficient 	& $\ttbar$+0j ($\pbinv$) 	& $\ttbar$+1j ($\pbinv$) 	& $\ttbar$+2j ($\pbinv$) 	& Incl. $\ttbar$+2j 	& $\ttbar$ reco ($\pbinv$) 	\\
%   $\gR$ coefficient 	& Incl. $\ttbar$ + 2 jets ($\pbinv$) 	& $\ttbar$ reco ($\pbinv$) 	\\
%   \hline
%   \hline
%   -0.2  		& 3.34036				& 0.947244 			\\
%   -0.15		& 4.01717				& 1.13624			\\
%   -0.1 		& 4.84056				& 1.36448			\\
%   -0.05		& 5.82329 				& 1.63952			\\
%   0.0 		& 6.98981 				& 1.96892			\\
%   0.05		& 8.37733 				& 2.36027			\\
%   0.1 		& 10.0153 				& 2.82111			\\
%   0.15		& 11.9024 				& 3.35903			\\
%   0.2 		& 14.0873 				& 3.98157			\\
%   \hline
%  \end{tabular}
%\end{table}

\subsection{Matrix element event cleaning} \label{subsec::EvtCleaning}

A first glance at the measurement of the right-handed tensor coupling did not resulted in the expected outcome to be retrieved.
However, since the cross-section values have been determined with great care and moreover the linearity test has proven that both the developed model and method behave accordingly, this discrepancy is most probably caused by the/a different \textbf{nature/performance} of reconstructed events.
\\

A closer look at the issue seemed to indicate that the deviating effect originates from events badly handled by the Matrix Element method, an occurence that should be investigated in detail.
Before any action can be taken to limit the influence of these events, the main difference between generator-level and reconstructed events should completely be understood.
%
%Analysing reconstructed collision events using a Matrix Element method deviates significantly from any generator-level study, mainly because the former type of events tend to be influenced by detector inefficiencies, ill-defined kinematic variables or wrongly reconstructed event topologies. However, the Matrix Element method will treat all events as if they were real semi-leptonic top-quark pair decays, and any inconsistency from the expected topology is likely to result in the underlying mathematical framework to misdetermine the event probability.
%Therefore it is of crucial importance a procedure is developed in order to exclude the contribution of these sort of events, for which the details will be given in Section~\ref{subsec::EvtCleaning}.
%\\
%Unfortunately these type of events can become rather significant since on average they appear to get a lower value assigned than well-converging events. Since the event probability is converted into a $\chi^{2}_{MEM}$ or $-\ln(\mathcal{L}_{MEM})$, events with a lower value actually contribute the strongest to the overall result. Hence, special care should be awarded to these type of misidentified events and they should be excluded in order not to bias the outcome.
%The influence of these type of events can be seen from Figure~\ref{fig::SMLik}, which contains the $\chiSqMEM$ of the $\gR$ = $0.0$ configuration for each event. This distributions shows a clear tail which does not exist for generator-level events, given in the right-handed figure.

\paragraph{Characteristics of reconstructed events} \hfill \\ %Understanding the nature of the \textit{bad} events

The first measurement of the $\gR$ coefficient has been performed using reconstructed $\ttbar$ events for which the four jets have been correctly matched with the generator-level parton, in order to ensure the Standard Model configuration would be retrieved. This simulation sample should not be influenced by badly reconstructed event topologies and, especially due to the stringent event-selection applied, result in an almost impeccable agreement with the expectation.
\\
However, this was certainly not the case since the obtained $-\ln(\mathcal{L}_{MEM})$ distribution corresponded to a decreasing straight line such that the minimum was located at the edge of the considered range. This large discrepancy, in contradiction with the credibility established (on the model) by the linearity test, necessitated a thorough comparison of the (different) treatment of generator-level and reconstructed events by the Matrix Element method.
\\

In order to identify whether a specific type of events with a distinguishing signature is responsible for this \textbf{discrepancy}, an exhaustive study has been performed.
Numerous variables have been looked at in order to find any indication for the disagreement between the generator- and reconstructed-level measurement, and the most promising one appeared to be the value of the $\chiSqMEM$-distribution evaluated at the Standard Model configuration.
\\
This distribution has a significantly different shape for generator-level and reconstructed events, as can be seen in Figure~\ref{fig::SMLik}.
The latter one \textit{contains} a prominent(\textit{ly visible}) tail, which is on the other hand completely absent for the generator-level events.
%***************************
% Necessary to mention something about the different starting value??
%***************************
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLikelihoodValue_GenEventsSM.pdf} \hspace{0.3cm}
 %Taken from directory: Events_CalibCurve/CalibCurve_SemiMu_RgR_AllDeltaTF_MGSampleSM_20000Evts_CutsAlsoOnMET/SMLikelihoodValue_GenEventsSM.pdf
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLikelihoodValue_RecoEvents_MyTF.pdf}
 %--> Update this!!
 \caption{Distribution of the $\chi^{2}_{MEM}$-value for the $\gR$ = $0.0$ configuration for both the generator- (left) and reconstructed-level (right) events.} \label{fig::SMLik}
\end{figure}

Now that a variable has been discovered which is capable of identifying the events most likely responsible for the observed discrepancy, the origin of this phenomenon should be understood in detail.
\\
First of all, the same minimum-extraction procedure has been applied onto a sample containing simulated $\ttbar$ events for which at least one jet has not been matched with the correct generator-level parton.
This allowed to compare both the outcome and this $\chi^{2}_{MEM}$ distribution with the previously considered sample containing only correctly reconstructed $\ttbar$ events.
The obtained results were identical, the minimum was also here located at the edge of the considered range and the $\chiSqMEM$ distribution was characterised by exactly the same tail, as can be seen in Figure~\ref{fig::SMLikCorrVSWr}.
%In case the tail of this distribution would be influenced by badly reconstructed event topologies, this would become clearly visible from this comparison.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/ScaledContribution_CWU_LumiNorm.pdf}
 \caption{Distribution of the $\chi^{2}_{MEM}$-variable evaluated at the Standard Model configuration for correctly reconstructed (green) and wronly reconstructed $\ttbar$ events. Both distribution have been \textbf{scaled accordingly}. \textit{Should still remove data and unmatched!}} \label{fig::SMLikCorrVSWr}
\end{figure}
From this comparison can thus clearly be concluded that the incorrect determination of the event topology is not causing the peculiar behaviour of the Matrix Element method.
This was already expected, since otherwise the discrepancy would not have been observed for the sample containing only correctly reconstructed events.
\\
\\
Next it has been investigated how such a significant tail can arise and why the Matrix Element seems to be incapable of handling a specific type of reconstructed events.
One of the more obvious differences between generator-level and reconstructed events is the tendancy to be influenced by detector inefficiencies and ill-determined kinematic variables. For the reconstructed events this is a significant point of concern, amplified by the fact that the resolution functions of these events allow the kinematics to \textit{vary} in a much wider range.
\\
Due to the conversion from the MadWeight likelihood distribution $\mathcal{L}_{MEM}$ into a $\chi^{2}$ distribution, the events residing in the tail correspond to events with a on average lower event probability.
This seems to suggest that the Matrix Element method assigns events for which the underlying mathematical framework cannot converge a lower event probability, which should thus be excluded.

%*************************
% Decide: Interesting to keep this TF part???
%*************************
%Finally, the importance of the applied resolution function can be visualised in Figure~\ref{fig::SMLikTF} which shows this $\chiSqMEM$ variable in case the resolution function developed in Section~\ref{sec::TF} is considered and otherwise in case the basic Gaussian function is used to describe the smearing of the \textbf{what exactly?}.
%Comparing these two shows a clear dependence on this resolution function, again indicating that the events in the end of the tail cannot converge since the reconstructed kinematic information does not agree with the expectation within the range allowed by the resolution function.
%\\
%\begin{figure}[h!t]
% \centering
% \includegraphics[width = 0.35 \textwidth]{image.png} %Maybe show the two on top of each other? This way repeating the same figure can be avoided!!
% \caption{Distribution of the $\chi^{2}_{MEM}$-value for the $\gR$ = $0.0$ configuration for the resolution functions created specifically for this analysis (green) and for the basic Gaussian resolution %function of the Matrix Element method (blue).} \label{Fig::SMLikTF}
%\end{figure}

\paragraph{Developing the event-cleaning procedure} \hfill \\

Even though the process responsible for the deviating behaviour is not completely mastered, it seems more than plausible that the reconstructed events are heavily influenced by inefficiencies non-existing for generator-level events. Moreover, the Matrix Element method is developed to treat every event as if it is a perfectly described semileptonic top-quark pair decay. Any inconsistency from the expected topology is likely to result in the event probability being misdetermined since the mathematical framework of the method is unable to converge.
Nonetheless, it has been established that the origin of this abnormal behaviour is not caused by the applied event-selection procedure but is a \textbf{true} feature of the Matrix Element method such that a strategy should be developed to reduce the contribution of these type of events.
\\

This event-cleaning procedure should be created carefully since only the events residing in the tail should be excluded. It is not the goal of this additional event-selection requirement to distinguish between well and badly reconstructed events since this is taken care of by the event selection criteria formulated in Chapter~\ref{ch::EvtSel}.
Especially since the fraction of these latter type of events is small compared to the former type, as can be seen from Figure~\ref{fig::SMLikCorrVSWrUnSc}. This contains the same two distributions as shown in Figure~\ref{fig::SMLikCorrVSWr}, with the only difference that now they are drawn on scale.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/RelativeContribution_CWU_LumiNorm.pdf}
 \caption{Distribution of the $\chi^{2}_{MEM}$-variable evaluated at the Standard Model configuration for correctly reconstructed (green) and wronly reconstructed $\ttbar$ events drawn on scale. \textit{Should still remove data and unmatched!}} \label{fig::SMLikCorrVSWrUnSc}
\end{figure}

In this analysis it has been opted for to decide on the optimal cut-value using the full sample of semi-leptonic $\ttbar$ events and selecting the value for which no bias in the outcome is observed.
Hence, several cut-values have been applied onto this sample for which the corresponding minimum has been determined, as can be seen in Figure~\ref{fig::CutValueFit}.
The considered cut-values range between 60 and 70, and can thus all be found in the outer range of the $\chiSqMEM$ distribution.
\\
Figure~\ref{fig::CutValueFit} also indicates the strong dependence of the obtained minimum on the applied cut-value, implying that its optimal value should be determined with great care in order to avoid introducing a significant bias. It also confirms that only the events in the tail should be excluded since the events located more in the intermediate region of the $\chiSqMEM$ distribution, so between $60$ and $65$ approximately, still contain relevant information and should be preserved for further analysis.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/LikCutFit_TTbarSemiLept.pdf}
 \caption{Minima obtained by applying different cut-values. This distribution has been fitted with a polynomial in order to determine the optimal cut-value, which correspond to the value for which no bias is recovered. \textit{Will zoom in on the region between 58 and 72! + put optimal point!}} \label{fig::CutValueFit}
\end{figure}

The overall distribution containing the minima corresponding to each cut-value is then fitted with a polynomial function, represented by the red curve in Figure~\ref{fig::CutValueFit}.
From this the optimal cut-value, corresponding to the outcome of $\gR$ = 0, can easily be determined as being $64.62$ $\pm$ $xx?$.
The effect of this event-cleaning procedure on the different samples has been summarised in Table~\ref{table::CutInfl}, which varies significantly for the considered samples.
\\
\begin{table}[h!t]
 \centering
 \caption{Influence of the event-cleaning procedure on the different samples.} \label{table::CutInfl}
 \renewcommand{\arraystretch}{1.2}
 \begin{tabular}{c|c}
  Sample 	& Event reduction 	\\
  \hline
  $\ttbar$ 	& $\%$ 			\\
  Single top 	& $\%$ 			\\
  W+jets 	& $\%$ 			\\
  Z+jets 	& $\%$ 			\\
  \hline
  Data 		& $\%$ 			
 \end{tabular}
\end{table}

%Even with the knowledge that the method behaving as should be and that the cross-section normalisation is applying the correct factor, the results obtained from the Matrix Element method need to surpass an additional cleaning procedure. This is a quality inherent to the inprecise determination of both the event kinematics and the event topology when considering reconstructed events. Any deviation from the expected topology might result in the the calculation technique not converging and thus misdetermining the event probability.

Within the Matrix Element method events containing useful information are supposed to be characterised by a $\chiSqMEM$ curve ...\\
\textit{From the added 2D plots no real conclusion can be drawn unfortunately. The second derivative distribution was a possibility, but since it is just almost symmetric around zero it would only raise more questions when adding this distribution ...\\ So it seems that no actual explanation will be able to be given for this cut ...\\ Especially because the 2D plots which can be given indeed show that something goes wrong at the outer x-axis range but the behaviour at lower x-values is not as expected either ...}
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/LnLikCut_ScatterPlot_SMLikvsMaxDelta_AllTT.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_ScdDerFine_CorrectTTbar.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_RightDeltaLnLik_CorrectTT.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_LeftDeltaLnLik_CorrectTT.pdf}
 \caption{2D plot for all $\ttbar$ events (so CWU combined -- scdDer only for correct ...). The two lower plots contain on the y-axis the $\chiSqMEM$ difference between $\gR$ = 0.0 and $\gR$ = $\pm$ 0.2. Hence in order to have minimum at zero, both should actually be negative!} \label{fig::SMLik2D}
\end{figure}

%\begin{figure}[h!t]
% \centering
% \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/Data_vs_SeparateTTbarJetsSemiLept_NotLumiScaled.pdf}
% \caption{} \label{fig::OptCutValue}
%\end{figure}


%--------------------------------------------------------------------------------------------------- \\
%Comparing the generator-level distribution with the one for the reconstructed events clearly shows that the events residing in the tail should be rejected. Considering different resolution functions has indicated that the shape and amplitude of the tail depends heavily on the applied resolution, indicating again that these type of events are less likely to be well reconstructed.
%Hence, the considered event-cleaning procedure will require the $\chi^{2}_{MEM}$ of each value to be lower than a specific cut-value. 
%\\
%
%The mentioned dependence on the resolution functions introduced for the reconstructed collision events can be visualised in Figure~\ref{fig::SMLikTF}, which contains this $\chiSqMEM$ variable at the $\gR$ = 0.0 point in case the resolution function developed in Section~\ref{sec::TF} is considered and in case a basic Gaussian function is used to describe the smearing of the \textbf{what exactly?}. 


\section{Results and systematics} \label{sec::Meas}

%\subsection{Bias of reconstructed events}
%The linearity test discussed in Section~\ref{subsec::CalibCurve} has indicated that the considered model does not introduce any biases and thus perfectly describes the decay of the top-quark. However, since %this calibration has been determined using generator-level events, a final cross-check is required to ensure no bias is introduced when applying the full event-selection chain.
%As mentioned before, the only simulation sample available describes the Standard Model configuration and can thus only be used to shift the calibration curve up or down depending on the obtained outcome.
%*****************************
% --> Not necessary since the cut-value is chosen as such that no bias is found!
%*****************************

\subsection{Pulls}

\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/PseudoExp_MinimumDistr_AllTTbarSemiLept.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/PseudoExp_UncDistr_AllTTbarSemiLept.pdf}
 \caption{Minimum and uncertainty distribution obtained for the 1000 considered pseudo experiments. (all semiLept TT)}  \caption{fig::MinAndUnc}
\end{figure}

\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/PullDistr_AllTTbarSemiLept.pdf}
 \caption{Pull distribution} \label{fig::PullDistr}
\end{figure}


