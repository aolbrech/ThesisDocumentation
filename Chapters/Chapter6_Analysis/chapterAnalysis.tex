\chapter{Measurement of anomalous couplings in top-quark pair decays} \label{ch::Analysis}

The technicalities of the Matrix Element method have been described in detail in Chapter~\ref{ch::MW} and will now be put to use in order to measure the anomalous couplings in the Wtb interaction vertex.
The main idea of the Matrix Element method, combining individual events probabilities into an overall negative log likelihood $\NegLL$, has been demonstrated with the simplified example of the top-quark mass determination.
The Matrix Element estimator $\hat{\epsilon}_{MEM}$ is obtained by minimising this distribution, and will be denoted as $\gREst$ for the measurement of the right-handed tensor coupling.
%The main idea of the Matrix Element method is that it combines all the individual event probabilities into an overall likelihood $\mathcal{L}_{MEM}$.
%This likelihood distribution is then transformed into a negative log likelihood, which is minimized in order to extract the Matrix Element estimator $\hat{\epsilon}_{MEM}$.
%In this chapter, which will focus on the measurement of the right-handed tensor coupling of the Wtb interaction vertex, the estimator of interest is denoted as $\gREst$.
However, before this measurement can be performed, a number of tests have to be carried out in order to ensure the Matrix Element estimator is behaving properly.
\\
%***********************
% Repeat MEM likelihood equation??
%***********************
\\
The performance of the Matrix Element estimator has to be studied carefully since this complex technique is likely to be influenced by the introduced assumptions.
Some of these simplifications might cause the value of this estimator to significantly deviate from the actual outcome expected from the Matrix Element method.
Hence a detailed investigation of the correspondence between the estimator and expectation will be performed in Section~\ref{sec::EstimatorProp}.
%Investigating the performance of the Matrix Element estimator, explained meticulously in Section~\ref{sec::EstimatorProp}, is crucial since the Matrix Element method can be influenced by the introduced simplifications/assumptions.
%the sometimes simplified \textit{representations}.
%Determining the correspondence between the result obtained from the Matrix Element estimator and the expected $\gR$-value will be done using simulated samples, for which the Standard Model configuration should be recovered.
%
%In the ideal case, the estimator $\hat{g_{R}}$ should be identical to the $\gR$ value extracted from the event-likelihood. 
%Nevertheless, this perfect behaviour can be influenced by ... (\textit{What can be responsible for a slope different from 1? Is it also just a bias?}) and result in a ... or a bias.
%
Once the required calibrations have been identified, the developed procedure to determine the Matrix Element estimator can be applied on the collision events collected by the CMS detector.
The final results obtained for the measurement of the right-handed tensor coupling of the Wtb interaction will be given in Section~\ref{sec::gRMeas}.

\section{Performance of the Matrix Element estimator} \label{sec::EstimatorProp} %Is method needed here? --> Otherwise call it 'Performance of the estimator $\hat{g_{R}}$'

In order to ensure the Matrix Element method behaves accordingly and results in the correct outcome, the entire procedure to calculate the estimator will be applied onto simulation samples.
For these types of events, which have been generated using the Standard Model configuration, the expected outcome is known. Hence any discrepancy between the value obtained for the Matrix Element estimator and the Standard Model ($\gR$ = 0) implies the developed procedure needs to be calibrated.
\\
The presence of such a discrepancy does not imply the Matrix Element method cannot be used, but simply means its outcome should be corrected for the non-optimal behaviour.
Possible reasons for such a deviation to occur are most likely found in the assumptions made for the created model describing the anomalous couplings or in the simplifications applied in the developed procedure.
\\

The first two performance tests focus on this correspondence between the outcome of the Matrix Element estimator $\gREst$ and the expectation $\gR^{MEM}$, which are supposed to be identical in the ideal case.
This has been visualised in Equation (\ref{eq::SlopeBias}) where the slope $a$ is the subject of the first test, the so-called linearity test, and is supposed to be equal to $1$. The bias $b$ for the developed procedure will be studied in the offset determination.
The third and last performance test which has been considered will focus on the statistical properties of the Matrix Element estimator.

%The value obtained from the Matrix Element estimator is supposed to correspond exactly to the information stored within the overall likelihood of the Matrix Element method.
%However, this ideal behaviour can be seriously influenced by assumptions made in the constructed model or by simplifications applied in the developed procedure and thus resultin a significant deviation from %the correct result.
%This is represented in Equation (\ref{eq::SlopeBias}), which shows the two aspects which will be studied in the first performance tests that have been carried out.
%These have as goal to determine the relation that exists between the result obtained from the estimator, $\gREst$, and the expected outcome of the $\chiSqMEM$ distribution, $\gR^{MEM}$.
%The final performance check will focus on the statistical properties of the estimator.
%Hence, two performance tests will be performed in order to determine the relation between the expected result and the obtained estimator value.  
%
%The applicability of the Matrix Element method can be seriously hampered by either the constructed model and the approximations made herein or otherwise by the procedure developed to extract the estimator from the event likelihood.
%Here the two possible deviations from the perfect behaviour will be discussed separately, first the linearity test which focusses on the slope and afterwards the presence of an offset will be checked.
\begin{equation} \label{eq::SlopeBias}
 \hat{g_R} = a \cdot \gR^{MEM} + b
\end{equation}
%For all these studies simulated events will be used since for these types of events the outcome should correspond to the Standard Model configuration.

\subsection{Linearity test}

%Why separate linearity test?
In this thesis it has been opted for to perform the linearity test separately from the offset determination, because the first one requires several samples generated with different coupling coefficients to be generated. Since this is a rather non-trivial task for reconstructed events, especially compared to the ease with which generator-level samples can be created, it has been decided generator-level events will be used for the linearity test. The created samples will contain 20 000 events in order to be comparable in size to the considered data sample.
The influence of the reconstructed events will be incorporated afterwards in the offset-determination study, which will thus only look at the outcome obtained for the Standard Model configuration.
\\

%What does the linearity test do, why a non-linear result can be obtained
The goal of the linearity test is to determine whether the outcome of the Matrix Element method depends on the considered coupling coefficient.
Such a behaviour can be expected in case the created model did not perfectly incorporate the physics processes taking place further away from the well-established Standard Model configuration.
%depicts the physics processes in a too simplified manner.
This effect will be studied by comparing the calculated minimum of various samples, each generated with a different coupling coefficient, against the value used to create the sample.
%Therefore various samples will be created, each generated with a different coupling coefficient, and the obtained minimum of each sample will be compared with the value used to create it.
\\
\\
%Want to include some event selection cuts in order to take into account some discrepancies from here.
Another viable candidate to cause the obtained outcome to depend on the coupling coefficient is the applied event-selection procedure.
%Besides a simplified model, the event-selection procedure is also a viable candidate to cause a dependency of the outcome on the coupling coefficient.
This because the selection efficiency might change significantly due to the altered kinematics of the Wtb interaction when varying the coupling coefficients.
However, the full event-selection chain cannot be applied since the linearity test has been performed using generator-level events.
Nevertheless, the conditions existing for the reconstructed events will be mimicked partially by requiring the generated events to fulfil some basic event-selection criteria, which have been summarised in Table~\ref{table::GenCuts}.
%However, since generator-level events are considered the full event-selection chain cannot be applied but, in order to mimic the conditions of the reconstructed events partially, the generated events will have to fullfill some basic event-selection criteria. These have been summarised in Table~\ref{table::GenCuts}.
The identification and additional fine-tuning criteria are not taken into account, but are on the other hand not expected to depend on the considered value of the coupling coefficient.
\\
\begin{table}[h!t]
 \centering
 \caption{Basic event selection applied to the generator-level events in order to partially mimic the situation existing for the reconstructed collision events.} \label{table::GenCuts}
 \renewcommand{\arraystretch}{1.2}
 \begin{tabular}{c|c|c|c}
  Particle 	& $\pT$-cut 		& $\vert \eta \vert$-cut 	& $\Delta$R-cut 	\\
  \hline
  Jets 		& $>$ 30 $\GeV$ 	& $<$ 2.5			& $<$ 0.3		\\
  Muon		& $>$ 26 $\GeV$		& $<$ 2.1			& $<$ 0.3		\\
  Neutrino 	& $>$ 25 $\GeV$		& $<$ 2.5			& $<$ 0.3		
 \end{tabular}
\end{table}

%What is done and what is expected
The actual linearity test then proceeds and compares the minimum obtained from the Matrix Element method with the coupling coefficient imposed during the generation process, which should be identical in the ideal case.
%The generated samples, each containing 20 000 events in order to be comparable in size to the data sample, are then analysed by the Matrix Element method and the correspondence between the obtained minimum and the coupling coefficient imposed during the generation process is determined. 
%In the ideal case these two values should be identical, implying that both the model and the procedure developed to extract the estimator are behaving properly.
The outcome of the linearity test for this analysis is given in Figure~\ref{fig::CalibCurve}, which clearly indicates that the distribution of the minima can be described by a straight line with slope almost equal to $1$ ($a$ = 0.97). Even though the actual bias of the method bias will be determined afterwards using reconstructed events, the offset obtained here corresponds with the expectations ($b$ = 0.005) such that can be concluded that the Matrix Element method behaves properly when considering generator-level events.
\\
%What is shown in the figure, and which range is important.
The fit on the distribution, the actual linearity test, has only been applied in the range $\left[-0.17, 0.17\right]$ since this is the relevant region where the Standard Model configuration should be recovered. 
%However, due to the precision of the obtained results, the region of interest can be limited further to values of $\vert \gR \vert$ smaller than 0.1, for which the linear behaviour is clearly visible.
%\\
%Why deviation outside range!
The deviation from the expected distribution outside the region of interest are most likely caused by the simplifications applied in the constructed model. In order to perfectly describe the physics processes over the entire $\gR$ range a more profound theoretical description of the Wtb interaction vertex is required, which lies beyond the scope of this thesis.
\begin{figure}[h!t]
 \centering
 %\includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/CalibrationCurve_SlopeComparision_DifferentCuts.pdf}
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/LinearityTest_FitResult.pdf}
 \caption{Outcome of the linearity test based on generator-level events, for which the obtained curve is perfectly described by a straight line. Hence both the developed model and method behave as expected and no calibration is required.} \label{fig::CalibCurve}
\end{figure}
%********************************
%Question: Fit also done by excluding the outer bins?
%********************************
%
%Some conclusions
%The performed linearity test has clearly indicated that both the model and method are behaving accordingly and that the obtained results are independent of the considered coupling coefficient.
%Hence, no calibration is required to restore the expected linear behaviour of the Matrix Element method.

\subsection{Offset calibration} \label{subsec::CutValue}

The goal of this second performance test is to determine whether the outcome of the Matrix Element estimator is influenced by a bias.
Even though the linearity test has proven that an excellent agreement exists when analysing generator-level events, both for the slope and the bias, this cannot be generalised to reconstructed events.
Since this bias might be affected by the different nature of reconstructed events, it has been determined using the simulated events fulfilling the entire event-selection chain introduced in Chapter~\ref{ch::EvtSel}.
Applying the full analysis procedure on this sample of reconstructed events would ideally result in the Standard Model configuration.
In case a deviation from the expectation is observed, this bias will be taken into account and the final result will be calibrated accordingly. 
\\

However, from the first application of the Matrix Element method on reconstructed events could be concluded that the method should be adapted to ensure it is capable of handling these type of events.
Since the obtained $\NegLL$ distribution corresponded to a decreasing line with minimum located at the edge of the considered range, the observed discrepancy is more than merely a bias introduced by the developed procedure to determine the Matrix Element estimator.
A closer look at the issue indicated that this is most likely caused by a certain type of events the Matrix Element method is unable to analyse properly.
Hence before the actual measurement can proceed, the reason behind this deviating behaviour should be understood thoroughly such that a procedure can be developed to limit its influence.

\paragraph{Understanding the nature of reconstructed events} \hfill \\ %Understanding the nature of the \textit{bad} events

The inconsistent outcome obtained for generator-level on the one hand and reconstructed events on the other hand clearly suggest that the Matrix Element method behaves differently for the two types of events.
This is not completely unexpected since reconstructed events tend to be influenced by detector inefficiencies or ill-determined event kinematics.
However, the Matrix Element will treat all events as actual semi-leptonic top-quark pair decays, and any deviation from the expected topology is thus likely to result in an incorrect event probability.
\\

The study, which has been performed in order to understand this deviating behaviour observed for reconstructed events, will first focus on a sample of selected $\ttbar$ events for which the four jets have been correctly matched with the generator-level parton.
This way the contribution from badly reconstructed event topologies can be excluded and, in case the bias is also observed for this sample, can be concluded that the deviation is definitely inherent to the nature of reconstructed events.
%to exclude the contribution from badly reconstructed event topologies.
%In case the bias would also observed for this sample, it can be concluded that the deviation is definitely inherent to the nature of reconstructed events and not caused by a lower reconstruction efficiency.
\\
In order to determine whether the observed discrepancy is caused by a specific type of events with a distinct signature, several event-variables have been considered which allow to differentiate between well and badly behaving events.
%might explain the significant disagreement between the generator- and reconstructed-level measurement.
%an exhaustive study has been performed with the aim of finding an explanation for the 
The most promising variable encountered turned out to be the value of the $\NegLLEvt$ distribution evaluated for each event at the Standard Model configuration.
\\
\\
The distribution of this $\NegLLEvt$ variable a significantly different shape for generator-level and reconstructed events, as can be seen in Figure~\ref{fig::SMLik}.
For the correctly reconstructed $\ttbar$ events, shown on the left, a tail is clearly visible, which is on the other hand completely absent for the generator-level distribution, shown on the right.
The reconstructed-level distribution seems to suggest that a fraction of events are given a lower event probability, and thus higher $\NegLLEvt$ value, in case the Matrix Element is unable to correctly analyse the kinematics of the considered event.
%***************************
% Necessary to mention something about the different starting value??
%***************************
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLikelihoodValue_MG.pdf} \hspace{0.3cm}
 %Taken from directory: Events_CalibCurve/CalibCurve_SemiMu_RgR_AllDeltaTF_MGSampleSM_20000Evts_CutsAlsoOnMET/SMLikelihoodValue_GenEventsSM.pdf
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLikelihoodValue_RECO.pdf}
 %--> Update this!!
 \caption{Normalised distribution of the $\NegLLEvt$ value for the $\gR$ = $0.0$ configuration for both the generator- (left) and reconstructed-level (right) events.} \label{fig::SMLik}
\end{figure}

In order to ensure this behaviour is not influenced by wrongly reconstructed event topologies, the same procedure has also been applied onto a sample containing simulated $\ttbar$ events for which at least one jet has not been matched with the correct generator-level parton.
This allowed to compare both the outcome of the Matrix Element estimator and the distribution of this $\NegLLEvt$ variable with the previously considered sample containing only correctly reconstructed $\ttbar$ events.
The obtained results were both identical such that can be concluded that the incorrect determination of the event topology is not causing the peculiar behaviour of the Matrix Element method, but that it is an undesirable drawback of applying this complex technique on reconstructed collision events.
\\
Figure~\ref{fig::SMLikCorrVSWr} contains the normalised distributions of the $\NegLLEvt$ variable evaluated at the SM configuration for the two considered $\ttbar$ samples.
Even though some differences clearly exist between the two samples, the position of the peak and the relevance of the intermediate region for example, the tail of this distribution is almost identical.
So this clearly demonstrates that the Matrix Element method treats events with a wrong event topology differently, but also confirms that these type of events are not responsible for the discrepancy observed for reconstructed events.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/ScaledContribution_CWU_LumiNorm.pdf}
 \caption{Normalised distribution of the $\NegLL$-variable evaluated at the Standard Model configuration for correctly reconstructed (green) and wrongly reconstructed $\ttbar$ events. \textit{Should still remove data and unmatched! + SCALE TO 1!}} \label{fig::SMLikCorrVSWr}
\end{figure}

A final study which has been performed attempts to find an explanation for the peculiar behaviour observed for the reconstructed events by investigating the dependence of other event variables on this $\NegLLEvt$ variable.
The goal is to find a distinguishing feature that could be used to reject the events negatively affecting the output of the Matrix Element method.
In order to be unaffected by other influences, only the $\ttbar$ sample containing events for which the topology is correctly reconstructed has been considered.
\\
In this study it has been chosen to focus on the distribution of the event probabilities calculated by the Matrix Element method.
This distribution should, once the probabilities are converted into a negative log likelihood, correspond to a parabola with minimum located at the Standard Model configuration.
However, it should be noted that studying event-based variables for the Matrix Element method is rather challenging since this technique requires enough statistics in order to be sufficiently accurate.
%which should correspond in the ideal case to a parabola with minimum value located at $\gR$ = 0 once converted into a negative log likelihood.
%The different variables which have been considered are all related to the steepness of this distribution such that can be visualised for how many events the expected behaviour is recovered.
\\

The dependence of these variables on the $\NegLLEvt$ variable are shown in Figure~\ref{fig::SMLik2D}, where this variable is each time placed on the $x$-axis.
The upper left histogram contains the maximum difference observed for the $\NegLLEvt$ distribution, thus indicating the importance of this event in the overall Matrix Element method likelihood since events with a large difference influence the overall shape the most. 
This clearly indicates that most events have a rather flat shape, with the exception of some outliers located mainly at low values of this $\NegLLEvt$ variable. However, a significant deviation is visible once the $\NegLLEvt$ variable becomes larger than approximately $65$, which is also the position of the tail in Figure~\ref{fig::SMLikCorrVSWr}.
\\
The upper right histogram shows the value of the second derivative of the parabola drawn through the point $\gR$ = $0$ and the two surrounding points ($\gR$ = $\pm$ $0.05$). 
%\textbf{This will be the standard method!!}
For the main bulk of events this value is small but still slightly positive, indicating that the corresponding parabola is rather flat. However, for higher values of this $\NegLLEvt$ variable, the value obtained for this second derivative starts to behave unexpectedly.
\\
In the lower two histograms the difference of the $\NegLLEvt$ variable between the Standard Model configuration and the outer left or right $\gR$ value is plotted.
%This value is related with the maximum observed difference, with the exception that the former one depends more on the expected shape of the $\NegLLEvt$ distribution.
This difference should be negative for the outer left $\gR$ variable and positive for the outer right one in order to have a parabola with minimum located at $\gR$ = 0.
%In order to have a nice parabola with minimum located at $\gR$ = 0, implying that this difference should be negative for the outer left $\gR$ variable and positive for the outer right one.
Also here the desired behaviour is recovered partially for events with a low $\NegLLEvt$ value, but starts to deviate once this variable becomes larger than $65$.
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/LnLikCut_ScatterPlot_SMLikvsMaxDelta_AllTT.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_ScdDerFine_CorrectTTbar.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_LeftDeltaLnLik_CorrectTT.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_RightDeltaLnLik_CorrectTT.pdf}
 \caption{Dependence of some event-variables on the $\NegLLEvt$ variable, which is always depicted on the $x$-axis. The considered values are the maximum difference of the $\NegLLEvt$ distribution (upper left), the value of the second derivative in the Standard Model configuration (upper right) and the difference between the $\NegLLEvt$ variable at $\gR$ = 0 and $\gR$ = $\pm$ 0.2.} \label{fig::SMLik2D}
\end{figure}

Unfortunately, the different variables that have been considered did not allow to verify which effect is causing the Matrix Element method to misdetermine the event probabilities of some specific events.
However, the distributions in Figure~\ref{fig::SMLik2D} clearly indicate that for each of these variables some unexpected behaviour occurs once the $\NegLLEvt$ becomes larger than a specific value.
Hence, the only option to reduce the influence of the events the Matrix Element is incapable of handling, is by limiting the value of this $\NegLLEvt$ variable for each event.
It is rather important to discard the events located in the tail of the distribution since they contribute on average the most to the overall $\NegLL$ distribution from which the Matrix Element estimator is extracted.
%This is necessary since the events located in the tail of the distribution become rather important because they contribute on average the most to the overall $\NegLL$ distribution from which the value of the Matrix Element estimator is \textit{extracted/determined}.

\paragraph{Matrix Element event-cleaning procedure} \hfill \\

The event-cleaning procedure needs to be developed carefully in order to ensure it only excludes the events residing in the tail of the $\NegLLEvt$ distribution.
No attempt should be made to reduce the contribution of badly reconstructed event topologies since this is already taken care of by the event-selection criteria formulated in Chapter~\ref{ch::EvtSel}.
In addition, the fraction of these type of events is almost negligible compared to the correctly reconstructed events, as can be seen in Figure~\ref{fig::SMLikCorrVSWrUnSc}. 
This again shows the distribution of the $\NegLLEvt$ variable for both type of events, as was the case in Figure~\ref{fig::SMLikCorrVSWr}, with the exception that here the number of events has not been normalised.
Hence the relative contribution of the two considered samples is clearly dominated by the sample containing the correctly reconstructed event topologies
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/RelativeContribution_CWU_LumiNorm.pdf}
 \caption{Distribution of the $\NegLLEvt$ variable evaluated at the Standard Model configuration for correctly reconstructed (green) and wrongly reconstructed $\ttbar$ events. \textit{Should still remove data and unmatched!}} \label{fig::SMLikCorrVSWrUnSc}
\end{figure}

From the studies performed previously could be concluded that the output of the Matrix Element method starts to behave incorrect as soon as the value of the $\NegLLEvt$ variable becomes larger than about $65$.
However in order to decide on the optimal cut-value to apply, it has been opted for in this thesis to determine the influence of several cut-values and select the one for which no offset exists.
%For this 
\\
This is an acceptable approach since in case the Matrix Element method would originally have been capable of dealing with reconstructed events, any observed bias would have been corrected for.
In contrast, the procedure followed now will adapt the procedure to extract the Matrix Element estimator by ensuring that the reconstructed events treated correctly and thus unaffected by an offset.
For this cut-value determination, the entire collection of selected events passing the full event-selection chain will be used.
%In contrast, the procedure followed now requires to adapt the output of the Matrix Element method in order to be capable of analysing these type of events.
%Hence it is correct to choose the necessary improvements in such a way that the outcome obtained from the Matrix Element estimator $\gR$ correspond with the Standard Model prediction.
\\

%The actual determination of this cut-value starts by scanning over the relevant region of the $\NegLLEvt$ distribution.
Since the most optimal cut-value is most likely located around $65$, the range of interest of the $\NegLLEvt$ distribution has been restricted between 60 and 70.
This region has been scanned over in steps of $1$ and for each cut-value, the obtained value of the Matrix Element estimator $\gREst$ is determined.  % and stored in Figure~\ref{fig::CutValueFit}.
The result for the different cut-values is given in Figure~\ref{fig::CutValueFit} and clearly shows the sensitivity of the Matrix Element estimator outcome on the applied cut-value.
\\
The overall distribution of the obtained minima is then fitted with a polynomial of degree $3$ in order to ensure the distribution is perfectly described by the curve of the fit in the region of interest.
From this the $\NegLLEvt$ value is determined for which no bias is observed, corresponding to a cut-value of $63.87$.
%In order to determine for which $\NegLLEvt$ cut-value no bias is observed, the overall distribution is fitted with a polynomial of degree $3$ to ensure the obtained curve is perfectly described in the region of interest.
%This has resulted in a cut-value of $63.87$, for which a corresponding $\gR$-value of $-0.001$ $\pm$ $0.009$ is recovered. % statistically compatible with $0$.
%The procedure then continues by fitting this distribution with a polynomial of degree $3$ to ensure the curve perfectly describes the minima in the interested region. From this fit the cut-value of the $\NegLLEvt$ variable at the Standard Model configuration is determined for which the obtained minima of the $\gR$ coupling coefficient corresponds to $0$.
%Hence, a cut-value of $63.869$ has been recovered, which results in a $\gR$-value equal to $-0.001$ $\pm$ $0.009$; statistically compatible with $0$.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/MinComp_MCOnly_StraightLineAtZero.pdf}  %Data lumi used (be consistent)!
 \caption{Minima obtained by applying different cut-values. This distribution has been fitted with a polynomial in order to determine the optimal cut-value, which correspond to the value for which no bias is recovered.} \label{fig::CutValueFit}
\end{figure}

%Result obtained for all MC samples combined!
With this $\NegLLEvt$ cut applied, not only the minimum is recovered at the correct location but also the obtained $\DeltaChi$ curve corresponds nicely with the expected Gaussian behaviour.
This curve, which is fitted with a quadratic function in order to determine the optimal value of the Matrix Element estimator, is given in Figure~\ref{fig::MinNominal}.
The value of $\gR$ which is extracted from this function for the full collection of simulated events corresponds to -0.0015 $\pm$ 0.0089, which is statistically compatible with $0$.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/MinimumDistribution_MC.pdf}
 \caption{Obtained $\DeltaChi$ distribution for all simulated samples after requiring the $\NegLLEvt$ variable evaluated at the Standard Model configuration to be larger than $63.87$. Due to the construction of this cut-value, the obtained minimum is statistically compatible with $0$.} \label{fig::MinNominal}
\end{figure}

%Hence, the events located more in the intermediate region of the $\chiSqMEM$ distribution, between $60$ and $65$ approximately, still contain relevant information and should be preserved for further analysis.
%\\

%*********************************
% Relevant to mention something of the influence of this cut??
%*********************************
%The effect of this event-cleaning procedure on the different samples has been summarised in Table~\ref{table::CutInfl}, which varies significantly for the considered samples.
%\begin{table}[h!t]
% \centering
% \caption{Influence of the event-cleaning procedure on the different samples. RELEVANT??} \label{table::CutInfl}
% \renewcommand{\arraystretch}{1.2}
% \begin{tabular}{c|c}
%  Sample 		& Event reduction 	\\
%  \hline
%  $\ttbar$ (good)	& $\%$ 			\\
%  $\ttbar$ (wrong) 	& $\%$ 			\\
% \end{tabular}
%\end{table}

%*************************
% Decide: Interesting to keep this TF part???
%*************************
%Next it has been investigated how such a significant tail can arise and why the Matrix Element seems to be incapable of handling a specific type of reconstructed events.
%One of the more obvious differences between generator-level and reconstructed events is the tendancy to be influenced by detector inefficiencies and ill-determined kinematic variables. For the reconstructed events this is a significant point of concern, amplified by the fact that the resolution functions of these events allow the kinematics to \textit{vary} in a much wider range.
%
%The importance of the applied resolution function can be visualised in Figure~\ref{fig::SMLikTF} which shows this $\chiSqMEM$ variable in case the resolution function developed in Section~\ref{sec::TF} is considered and otherwise in case the basic Gaussian function is used to describe the smearing of the \textbf{what exactly?}.
%Comparing these two shows a clear dependence on this resolution function, again indicating that the events in the end of the tail cannot converge since the reconstructed kinematic information does not agree with the expectation within the range allowed by the resolution function.
%\\
%\begin{figure}[h!t]
% \centering
% \includegraphics[width = 0.35 \textwidth]{image.png} %Maybe show the two on top of each other? This way repeating the same figure can be avoided!!
% \caption{Distribution of the $\chi^{2}_{MEM}$-value for the $\gR$ = $0.0$ configuration for the resolution functions created specifically for this analysis (green) and for the basic Gaussian resolution %function of the Matrix Element method (blue).} \label{Fig::SMLikTF}
%\end{figure}

%Possible conclusion:
Even though the process responsible for the deviating behaviour is not completely mastered, it seems more than plausible that the reconstructed events are heavily influenced by inefficiencies non-existing for generator-level events. Moreover, the Matrix Element method is developed to treat every event as if it is a perfectly described semi-leptonic top-quark pair decay. 
Hence, any inconsistency from the expected topology is likely to result in the event probability being misdetermined since the mathematical framework of the method is unable to converge.
Nonetheless, it has been established that the origin of this abnormal behaviour is not caused by the applied event-selection procedure but is a true feature of the Matrix Element method.
This implies it is allowed to develop a detailed event-cleaning procedure, which is intended to reduce the contribution of these type of events.
This can be accomplished if the value of the $\NegLLEvt$ variable evaluated at the Standard Model configuration is restricted for each event to be lower than $63.87$ and will therefore be applied in the remainder of this analysis.


\subsection{Statistical properties} \label{subsec::StatProp}

The third and final test which has been performed in order to ensure the Matrix Element estimator $\gREst$ behaves properly is related to its statistical properties.
This is a necessary aspect to study since it allows to understand whether the uncertainty obtained from the estimator is correct. If this value would be over- or underestimated, the uncertainty of the final result will need to be calibrated accordingly.
\\
%The developed technique to extract the relevant information from the Matrix Element method has proven to be uninfluenced by any bias, as has been shown in Section~\ref{sec::CalibCurve}.
%Furthermore, the optimal cut-value for the event-cleaning procedure is chosen as such that the expected Standard Model value is recovered for the simulated events. 
%Since the remaining simulation samples are all almost negligible compared to this one, the leading background contribution in this analysis is single-top production in the tW-channel which is about 50 times smaller, no significant influence on the overall outcome is expected from these types of events.
\\
%However, additional research is still required in order to make sure the statistical properties of this analysis are well described.
The statistical properties of this estimator are evaluated using a resampling technique which generates a set of samples by randomly selecting events from the full collection of simulated samples until the data luminosity of $19.6$ $\fbinv$ is reached.
The considered events are all required to pass the full set of event-selection criteria, including the $\NegLLEvt$ cut-value discussed earlier, such that their average result should correspond to the Standard Model configuration.
%in accordance with a previously specified luminosity, in general the luminosity of the data sample.
%This allows to obtain a representation of actual data and to verify whether the average result can be compared with expectation.
%Each of these generated samples is then treated as an actual data sample and the full analysis is applied in order to determine the distribution of both the 
\\

Due to the considerable size of the simulated samples compared to the data sample, $1 000$ of these samples, or so-called pseudo-experiments, can be created without introducing a significant correlation between the different pseudo-experiments.
Each of these samples is a representation of the data sample and will be treated as such by the developed procedure to extract the Matrix Element estimator, for which the distribution of the minimum $g_{R,i}$ and corresponding uncertainty $\sigma_i$ is given in Figure~\ref{fig::MinAndUnc}.
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/PseudoExperiments_MinimumDistr_AllMC.pdf} \hspace{0.5cm}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/PseudoExperiments_UncDistr_AllMC.pdf}
 \caption{Minimum and uncertainty distribution obtained for the 1000 considered pseudo experiments. The average value of the minimum distribution corresponds to $-0.0018$ $\pm$ $0.0089$, implying that no bias exists for the Matrix Element estimator $\gREst$.}  \label{fig::MinAndUnc}
\end{figure}

From the outcome of the Matrix Element estimator, shown on the left in Figure~\ref{fig::MinAndUnc}, the mean value of the right-handed tensor coupling $\left\langle \gR \right\rangle$ can be obtained using a Gaussian fit.
This value corresponds to the average bias observed for the $1 000$ considered pseudo-experiments and, since it is equal to $\gR$ = $-0.0018$ $\pm$ $0.0089$, confirms that the presence of an offset is taken care of by the applied cut-value.
The pull, for which the distribution should correspond to a Gaussian function with mean of $0$ and width of $1$, can then be obtained using:
%then allows to determine the bias and pull distribution via
%From the distribution on the right, containing the result of the estimator $\gREst$, the mean value of the right-handed tensor coupling can be determined.
%This value, denoted as $\left\langle \gR \right\rangle$ then allows to determine the bias and pull distribution via
%These values are then compared to the expected results such that the average bias and pull distribution can be determined via
\begin{equation}
 \textrm{pull}_{i} = \frac{g_{R,i} - \left\langle \gR \right\rangle}{\sigma_{i}}
\end{equation}
%The obtained bias is equal to , which is as expected statistically compatible to $0$ since the cut-value has been chosen as such to be free of any offset.
The obtained distribution for the pull is given in Figure~\ref{fig::PullDistr}, which clearly corresponds with the expected behaviour.
The value of the width is equal to $0.979$ $\pm$ $0.025$, implying a perfect agreement is observed and thus no calibration is required in order to describe the statistical properties of the Matrix Element estimator.
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/PseudoExperiments_PullDistr_AllMC.pdf}
 \caption{Pull distribution obtained for the 1000 considered pseudo-experiments, which can be described by a Gaussian function with mean = $-0.0003$ $\pm$ $0.0316$ and width = $0.979$ $\pm$ $0.025$.} \label{fig::PullDistr}
\end{figure}

\section{Measurement of $\gR$ with the Matrix Element method} \label{sec::gRMeas}

The different performance tests discussed in the previous section have clearly indicated that the Matrix Element estimator $\gREst$ is behaving accordingly.
Hence the full analysis procedure can now be applied on the data events collected by the CMS experiment in order to determine the value of the right-handed tensor coupling of the Wtb interaction.

\subsection{Results on data}
Following the same procedure, the $\DeltaChi$ values obtained from the integration of the Matrix Element method for each $\gR$ configuration in the considered range are given in Figure~\ref{fig::MinData}.
The outcome of the Matrix Element estimator is then determined by fitting the obtained $\DeltaChi$ curve with a 2$^{nd}$ degree polynomial, since a Gaussian behaviour is assumed.
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.75 \textwidth]{Chapters/Chapter6_Analysis/Figures/MinimumDistribution_Data.pdf}
 \caption{Obtained $\DeltaChi$ distribution for the data-sample at $8 \TeV$.} \label{fig::MinData}
\end{figure}

Applying the minimisation method on this fitted function results in a $\gR$-value for the selected data events of:
\begin{equation} \label{eq::DataResult}
 \gR = 0.0071 \pm 0.0083
\end{equation}
This value of the right-handed tensor coupling of the Wtb interaction vertex indicates an excellent agreement with the Standard Model, indicating that this measurement did not observe any influence of anomalous couplings in the decay of top-quark pairs.
The statistical uncertainty obtained for the data events can be compared with the uncertainty expected from the study of the statistical properties of the Matrix Element estimator, which have been discussed in Section~\ref{subsec::StatProp}.
Also here an excellent agreement is obtained.

\subsection{Systematic uncertainties}

Several systematic effects might change the outcome of the Matrix Element estimator and their influence should be carefully investigated.
Such a systematic uncertainty can can be caused by several sources: an incomplete understanding of the detector performance which then results in an incorrect modelling of the simulation, the assumptions made in the likelihood-extraction procedure, or even by the algorithms used during the reconstruction process.
%*************************
% Is this last one correct ? Is there any systematic that I'm studying which is influenced by this ... (Or should jet reconstruction actually be insensitive to JES if it would be well reconstructed)...
%*************************
\\
Their effect can in general be determined by varying the parameter responsible for the considered systematic uncertainty up- and downwards with one standard deviaton for the entire collection of considered simulation samples.
The average difference between the two obtained $\gR$-values is defined as the systematic uncertainy in this analysis, unless if the corresponding statistical uncertainty is larger than the actual systematic uncertainty.
\begin{equation} \label{eq::Syst}
 \Delta \gR =  \frac{\vert \gR^{\textrm{down}} - \gR^{\textrm{up}} \vert}{2} %\pm \frac{\sqrt{\sigma(\gR^{down})^2 + \sigma(\gR^{up})^2}}{2}
\end{equation}

The complexity of the Matrix Element method has an important consequence for the way the systematic uncertainties are evaluated in this analysis.
Since for some of the considered systematic effects this up- and downwards shift results in altered kinematics, the entire Matrix Element method has to be repeated.
Normally this should be done for all considered simulation samples but due to the long processing time this would involve, it has been opted for to only consider the relevant samples.
\\
This is an acceptable approach to take since the contribution of the considered background samples is almost negligible due to the stringent event selection.
Their small relative contribution to the overall $\NegLL$ value implies that the background samples almost do not influence the overall $\gR$-value.
However, since the different background samples are statistically limited, no individual $\gR$ measurement can be performed. 
Nevertheless, a combination with the signal sample is possible such that a $\gR$-value can be extracted from the corresponding combined $\DeltaChi$ curve.
The outcome obtained for the different background samples is summarised in Table~\ref{table::BckInfl}.
\\
\begin{table}[h!t]
 \centering
 \caption{Obtained result of the Matrix Element estimator when combining the signal sample ($\ttbar$) with the different background samples considered. (\textit{Use MC lumi for unc?})} \label{table::BckInfl}
 \renewcommand{\arraystretch}{1.2}
 \begin{tabular}{|c|c|}
  \hline
  Sample 			& Extracted $\gR$-value 			\\
  \hline
  $\ttbar$ 			&  0.0013 $\pm$ 0.0090		\\
  $\ttbar$ + Single top 	&  -0.0010 $\pm$ 0.0089		\\
  $\ttbar$ + W-jets  		&  0.0009 $\pm$ 0.0090		\\
  $\ttbar$ + Z-jets 	 	&  0.0013 $\pm$ 0.0090		\\
  \hline
  Total simulation 		& -0.0015 $\pm$ 0.0089 		\\
  \hline
 \end{tabular}
\end{table}

Table~\ref{table::BckInfl} clearly indicates that only the contribution of the single-top quark decays affects the obtained $\gR$-value.
Hence this simulation sample will still be taken into account for the computation of the jet energy scale uncertainty, which is expected to be one of the dominating systematic effects of this measurement.
The systematic uncertainty corresponding to the jet energy resolution on the other hand is presumed to be much smaller and will therefore be determined using only the signal $\ttbar$ sample.
Nevertheless, since the up- and downwards shift of the relevant parameter are compared to eachother, the obtained systematic uncertainty is not supposed to depend heavily on the set of simulation samples considered.
\\
\\
The remaining systematic uncertainties that have been studied do not change the kinematics of the event, but simply alter the relative contribution of each event to the overall $\NegLL$ value. 
Hence the full set of simulation samples will be considered for these systematic effects, which are believed to be less significant in this analysis since they only shift the overall $\DeltaChi$ curve up- or downwards without actually altering its shape.
Besides the fact that the samples already have been created and thus no effort is required to use all simulated samples, this also has as advantage that in case the considered systematic is dominated by the corresponding statistical uncertainty this value is determined using all the available statistics.
\\

Once the method to assess the different systematic uncertainties has been established, their effect has been propagated to the outcome of the Matrix Element estimator.
The influence of each considered systematic uncertainty can be found in Table~\ref{table::SystValues}, where the values highlighted using boldface font represent the actual uncertainty used to determine the total systematic effect.
From this summarised overview can directly be concluded that the majority of the considered systematic uncertainties is dominated by the corresponding statistical uncertainty and thus have a very small
influence.
A more detailed evaluation of the different systematic uncertainties can be found below.
\\
\begin{table}[h!t]
 \centering
 \caption{Overview of the different systematic uncertainties considered for the measurement of the right-handed tensor coupling $\gR$. For each contribution the larger among the estimated shift and its statistical uncertainty is quoted, as indicated by the bold script.} \label{table::SystValues}
 \renewcommand{\arraystretch}{1.2}
 \begin{tabular}{|c|c|}
  \hline
  Source 				& Estimated effect on $\gR$ 	\\
  \hline
  Likelihood extraction procedure 	& \textbf{0.0071} $\pm$ 0.0030 	\\
  Jet energy scale 	 		& \textbf{0.0056} $\pm$ 0.0018 	\\
  Jet energy resolution 		& 0.0010 $\pm$  \textbf{0.0019} 				\\
  b-tagging efficiency 			& 0.00001 $\pm$ \textbf{0.00185} 	\\
  mis-tagging efficiency  		& 0.00004 $\pm$ \textbf{0.00185} 	\\
  Pileup reweighting  			& 0.0008 $\pm$ \textbf{0.0019} 	\\
  Background composition 	 	& 0.0011 $\pm$ \textbf{0.0019} 	\\
  %Matching 				& \textcolor{red}{0.0097 $\pm$ 0.0059}		\\
  %Scaling 				& \textcolor{red}{Something wrong ...}		\\
  \hline
  Total 				& 0.010				\\
  \hline
 \end{tabular}
\end{table}

%\newpage
\begin{myindentpar}
  \begin{description}
    \item[Likelihood-extraction procedure -- Maybe give this later, or just drop] \hfill \\
    The most important systematic uncertainty of the performed measurement is related to the procedure developed to extract the $\gR$ coefficient from the $\DeltaChi$-curve obtained from the Matrix Element method.
    In this procedure it is assumed that the curve describing the $\DeltaChi$ points calculated by the Matrix Element method exhibits a Gaussian behaviour and can thus be fitted by a quadratic function.
    However, for the points located at the edges of the considered range, deviations from the expected shape start to appear and might influence the outcome.
    \\
    This possible systematic effect is taken into account by calculating the value of the Matrix Element estimator when the fit is restricted to the inner lowest points of the $\DeltaChi$ curve.
    Since this systematic has no up- and downscaling component, the uncertainty quoted in Table~\ref{table::SystValues} corresponds to the difference in result observed for the two methods.
    \\
    The obtained systematic uncertainty is rather large, which emphasises the significant difference between both approaches. This can be visualised in Figure~\ref{fig::MethodDiff} where both procedures have been applied on the entire collection of simulated events. 
    However, even though the alternative method is more precise it is missing valuable information obtained from the Matrix Element method further away from the Standard Model point. % where the contribution of the anomalous couplings is likely to be observed. 
    The discrepancy between the two methods can most likely be reduced if the scanned $\gR$-range is refined in the proximity of Standard Model configuration.
    %can be explained by the limited number of configuration points measured in the proximity of the minimum (and the lack of uncertainty of the Matrix Element method).
    \begin{figure}[h!t]
      \centering
      \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/MinimumExtractionMethod_MC.pdf}
      \caption{Comparison between the two considered likelihood-extraction procedures in order to determine the systematic uncertainty related to the curve used in the minimisation method. The dashed light-blue curve is obtained using only the three inner points while the solid red line corresponds to the standard method where only the two outer points are discarded from the fit.} \label{fig::MethodDiff}
     \end{figure}

    \item[Jet Energy scale] \hfill \\
    The energy of the reconstructed PF jets is calibrated using dedicated $\pT$- and $\eta$-dependent jet energy scale calibrations, as was explained in Section~\ref{subsec::JetReco}.
    Since the Matrix Element method evaluates in a direct manner the kinematics of the different final state particles in the event, this uncertainty should be propagated to the Matrix Element estimator.
    The effect of changing the jet energy on the outcome of the $\gR$ measurement is rather significant, but understandable since the considered event topology consists of four jets.
    %Since the considered event topology consists of four jets, it is expected that changing the jet energy has a significant effect on the $\gR$ measurement.
    %Due to the presence of four jets in the event topology, this is the most dominant systematic uncertainty for this analysis. (\textbf{Certain this is correct ...?})    
    
    %Since this probably affects the Transfer Functions the most, it would have been more correctly to calculate separate transfer functions for the JES up and down case ...
    
    \item[Jet Energy resolution] \hfill \\
    The different energy resolution observed in data and simulation requires the energy of the simulated events to be smeared using the JER correction factor.
    %However, since this change in energy can result in a different outcome of the Matrix Element method, the uncertainty on this $\eta$-dependent correction is taken into account.
    In order to evaluate the possible effect on the Matrix Element estimator, the systematic uncertainty originating from this $\eta$-dependent correction has been calculated but appears to be dominated by the corresponding statistical uncertainty.     
    
    \item[Efficiency of the b-jet identification] \hfill \\   %Is efficiency the correct word??
    The different efficiency for the b-jet identification algorithm resulted in $\pT$-dependent scale-factors, which are determined separately for light-flavoured and b- and c-flavoured jets.
    Even though the scale-factor itself is identical for the $b$- and $c$-quark jets, the uncertainty of the latter one is defined to be double as large. 
    Since the uncertainties of the light- and heavy-flavoured jets are assumed to be uncorrelated, they have been determined separately.
    In both cases, the obtained systematic uncertainty is negligible and is dominated by the statistical uncertainty.
    %\\
    %Here it has been chosen to determine the systematic uncertainty for the light- and heavy-flavoured jets separately, in order to follow the same procedure as is applied for the other systematic uncertainties. 
    %Both are dominated by the statistical uncertainty, which is expected since the applied event-selection criteria are developed to . 
    %It also implies that the Matrix Element method is capable of identifying the event topologies containing relevant information and is not influenced by these b-tag scale-factors. 
    %\textit{Should it be mentioned that especially the misTag effect is almost invisible?}
    
    \item[Pileup reweighting] \hfill \\
    %Shift the number of interactions with $\pm$ $5\%$.
    The number of additional pile-up interactions in simulation is obtained by reweighting the mean number of interactions in each event. 
    In order to estimate the effect of this systematic uncertainty, this mean number of interactions has to be shifted with $\pm$ $5\%$.  
    This takes into account the luminosity uncertainty, the uncertainty on the total inelastic cross-section and even an additional uncertainty to cover the pileup modeling.
    However, the performed measurementis insensitive to this reweighting procedure and the obtained systematic uncertainty is again dominated by the statistical uncertainty.
        
    \item[Background composition] \hfill \\
    A different composition of the background samples might alter the obtained $\gR$ value since it will change the relative contribution to the $\DeltaChi$ distribution.
    The corresponding uncertainty is calculated by varying the background fractions with $100\%$ while keeping the signal $\ttbar$ fraction fixed, which is an extremely conservative approach.
    However, as already could be deduced from the small effect of the different background samples on the overall simulated result, this systematic uncertainty is dominated by the statistical uncertainty.
    Hence no effort has been put into changing the background fractions with a less conservative value since the dominating contribution will remain the statistical uncertainty.
                
    %\item[Determination of cut-value] \hfill \\
                
    %\item[Matching and scaling] \hfill \\
    %Need to understand what is going wrong for these two samples ...!!
        
    %\item[Top $\pT$ reweighting (Still to check!!)] \hfill \\
    %Should this be added? (Hope this doesn't mean running MadWeight again ...)
    
    %\item[Muon SF (?)] \hfill \\
        
   \end{description}
\end{myindentpar}

%Mention why the cut-value and background contribution is not added as a systematic!
Besides the systematic uncertainties discussed above, this measurement is viable to an additional systematic effect that should be investigated in detail.
This corresponds to the application of the $\NegLLEvt$ cut-value, for which the optimal value is determined using simulation events as was discussed in Section~\ref{subsec::CutValue}.
In case the conditions for this $\NegLLEvt$ variable in data deviate from those in simulation, implementing this cut might introduce a bias for the data events and thus result in a systematic effect that should be taken into account.
\\
Hence it has been investigated whether the conditions are similar for data and simulation and whether the optimal cut-value for data corresponds with the one obtained from simulation.
At first the $\NegLLEvt$ variable evaluated at the Standard Model configuration is compared, as can be seen from the left distribution in Figure~\ref{fig::CutValue}.
Taking into account the statistical uncertainties on the data sample, an excellent agreement is observed. 
As a result, it is not expected that the determination of the optimal cut-value will introduce a discrepancy between data and simulation since the behaviour of the tail is similar for both.
The scan on the different cut-values is shown as the right plot of Figure~\ref{fig::CutValue} and, within the statistical uncertainties, confirms this statement.
\\
\\
The perfect agreement between data and simulation for this cut-value determination indicates that no systematic uncertainty needs to be taken into account for this procedure.
%Except for the systematic uncertainties listed above, another possible source responsible for introducing a systematic uncertainty on the performed measurement has been studied.
%It has been investigated whether the chosen $\NegLLEvt$ cut-value does not result in a systematic effect which might change the outcome of the Matrix Element estimator.
%Since such an effect can only occur in case the conditions in data events deviate from those in simulated events, which is used to calculate the optimal value, an excellent agreement between both should be %recovered.
%Hence the overall shape obtained distribution for this $\NegLLEvt$ variable evaluated at the Standard Model configuration has been compared and the cut-value determination has also been applied for the data %sample, as can be seen from Figure~\ref{fig::CutValue}.
%Taking into account the statistical uncertainties on data, this results in an almost identical outcome such that no additional systematic uncertainty for this cut-value is necessary.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.51 \textwidth]{Chapters/Chapter6_Analysis/Figures/StackedPlot_SMLikValue_AllMCAndData.pdf} \hspace{0.3cm}
 \includegraphics[width = 0.41 \textwidth]{Chapters/Chapter6_Analysis/Figures/MinComp_MSPlot_StraightLineAtZero.pdf}   %Same lumi used (data)!
 \caption{Evaluation of a possible systematic effect caused by the procedure to determine the optimal cut-value. The perfect agreement obtained for the distribution of the $\NegLLEvt$ variable (left) and the similar outcome, within the statistical uncertainties, for this cut-value (right) indicate no shift should be taken into account.} 
 \label{fig::CutValue}
\end{figure}

%Result obtained for JES is (Maybe possible to give the influence on this SMLik value and the different minimum functions?):
%\begin{eqnarray}
% \textrm{JES Minus: } & \gR = 0.00463076 \pm 0.002599 \\
% \textrm{JES Plus: }  & \gR = -0.00655865 \pm 0.00257043
%\end{eqnarray}

%Results obtained for matching are:
%\begin{eqnarray}
% \textrm{Matching down: } & \gR = 0.00733939 \pm 0.00810279 \\
% \textrm{Matching up: }   & \gR = 0.0267044 \pm 0.00856545
%\end{eqnarray}

%Results for b-tag systematic have to be combined for the light and b/c result.
%Obtained values are (only using AllTT):
%\begin{eqnarray}
% \textrm{Plus:} & \gR^{bc} = 0.00130204 \pm 0.00258509 \textrm{ and } \gR^{l} = 0.00139988 \pm 0.00264932 \nonumber \\
% \textrm{Minus:} & \gR^{bc} = 0.00133473 \pm 0.00272017 \textrm{ and } \gR^{l} = 0.00123783 \pm 0.00265251 \nonumber \\
% \textrm{Nominal:} & \gR = 0.00131995 \pm 0.00265084
%\end{eqnarray}
%Obtained values are (only using systMC):
%\begin{eqnarray}
% \textrm{Plus:} & \gR^{bc} = -0.00101574 \pm 0.00256493 \textrm{ and } \gR^{l} =  -0.000946789 \pm 0.00262858 \nonumber \\
% \textrm{Minus:} & \gR^{bc} = -0.00100316 \pm 0.00269887 \textrm{ and } \gR^{l} = -0.00107116 \pm 0.00263181 \nonumber \\
% \textrm{Nomina:} & \gR = -0.00100778 \pm 0.00263012
%\end{eqnarray}

%Results obtained for pileup reweighting (AllTT):
%\begin{eqnarray}
% \textrm{Plus:} & \gR =  0.000543221 \pm 0.00265971\\
% \textrm{Minus:} & \gR = 0.00225299 \pm 0.00264266 \\
% \textrm{Nominal:} & \gR = 0.00131995 \pm 0.00265084
%\end{eqnarray}


The combination of the considered systematic uncertainties with the $\gR$ measurement from the data sample results in a final $\gR$ value equal to:
\begin{equation}
 \gR = 0.0071 \, \pm \, 0.0083 \, (\textrm{stat.}) \, \pm \, 0.010  \, (\textrm{syst.})
\end{equation}
%This is compatible with the Standard Model hypothesis, which predicts the Wtb interaction is purely represented by the left-handed vector coupling $V_R$.
%Hence the absence of any anomalous couplings implies $\gR$ is supposed to be equal to $0$.
This is compatible with the Standard Model hypothesis, which corresponds to a right-handed tensor coupling of $0$; as is the case for the other anomalous couplings; such that the Wtb interaction can be uniquely represented by the left-handed vector coupling $V_L$.

