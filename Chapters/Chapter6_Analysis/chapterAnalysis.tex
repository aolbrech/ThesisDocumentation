\chapter{Measurement of anomalous couplings in top-quark pair decays} \label{ch::Analysis}

The previous chapter has described in detail the technicalities of the Matrix Element method and demonstrated its applicability using a simple example.
The main idea behind this method is that it combines all the individual event probabilities into an overall likelihood $\mathcal{L}_{MEM}$.
This likelihood distribution is then transformed into a negative log likelihood, which is minimized in order to extract the Matrix Element estimator $\hat{\epsilon}_{MEM}$.
In this chapter, which will focus on the measurement of the right-handed tensor coupling of the Wtb interaction vertex, the estimator of interest is denoted as $\gREst$.
\\
%***********************
% Repeat MEM likelihood equation??
%***********************

Before the actual measurement can be performed, a number of tests have to be carried out in order to ensure the Matrix Element estimator is behaving properly.
Investigating the performance of this estimator, explained meticulously in Section~\ref{sec::EstimatorProp}, is crucial since the Matrix Element method can be influenced by the introduced simplifications/assumptions.
%the sometimes simplified \textit{representations}.
Determining the correspondence between the result obtained from the Matrix Element estimator and the expected $\gR$-value will be done using simulated samples, for which the Standard Model configuration should be recovered.
%Hence, comparing the obtained result of simulated samples, where the outcome is known, with the value of the estimator allows to fix the correspondence between the estimator and the actual outcome.
%
%In the ideal case, the estimator $\hat{g_{R}}$ should be identical to the $\gR$ value extracted from the event-likelihood. 
%Nevertheless, this perfect behaviour can be influenced by ... (\textit{What can be responsible for a slope different from 1? Is it also just a bias?}) and result in a ... or a bias.
%
\\
Once all the ... the measurement itself will be discussed in Section~\ref{sec::gRMeas}.

\section{Performance of the Matrix Element estimator} \label{sec::EstimatorProp} %Is method needed here? --> Otherwise call it 'Performance of the estimator $\hat{g_{R}}$'

The applicability of the Matrix Element method can be seriously hampered by either the constructed model and the approximations made herein or otherwise by the procedure developed to extract the estimator from the event likelihood.
Here the two possible deviations from the perfect behaviour will be discussed separately, first the linearity test which focusses on the slope and afterwards the presence of an offset will be checked.

\begin{equation}
 \hat{g_R} = a \cdot \gR^{Lik} + bias
\end{equation}
The final performance check will focus on the statistical properties of the estimator.

\subsection{Linearity test}

%Why separate linearity test?
The choice to perform the linearity test separately from the offset determination is driven by fact that the linearity test requires information from several samples generated with different coupling coefficients. Since creating such samples for reconstructed events is a non-trivial task, especially compared to the ease with which generator-level samples can be created, it has been opted for in this thesis to use generator-level events for the linearity test.
The influence of the reconstructed events will be incorporated afterwards in the offset determination, which only requires the result of the Standard Model configuration.
\\

%What does the linearity test do, why a non-linear result can be obtained
The goal of the linearity test is to determine whether the outcome of the Matrix Element method depends on the coupling coefficient considered.
Such a behaviour can be expected in case the created model does not perfectly describes the physics processes taking place when moving away from the well-established Standard Model configuration.
%depicts the physics processes in a too simplified manner.
Therefore various samples will be created, each generated with a different coupling coefficient, and the obtained minimum of each sample will be compared with the value used to create it.
\\
\\
%Want to include some event selection cuts in order to take into account some discrepancies from here.
Besides a simplified model, the event-selection procedure is also a viable candidate to cause a dependency of the outcome on the coupling coefficient.
This because the selection efficiency might change significantly due to the altered kinematics of the Wtb interaction when varying the coupling coefficients.
However, since generator-level events are considered the full event-selection chain cannot be applied but, in order to mimic the conditions of the reconstructed events partially, the generated events will have to fullfill some basic event-selection criteria. These have been summarised in Table~\ref{table::GenCuts}.
The identification and additional fine-tuning criteria cannot be taken into account, but are on the other hand not expected to depend on the considered value of the coupling coefficient.
\begin{table}[h!t]
 \centering
 \caption{Basic event selection applied to the generator-level events in order to partially mimic the situation existing for the reconstructed collision events.} \label{table::GenCuts}
 \renewcommand{\arraystretch}{1.2}
 \begin{tabular}{c|c|c|c}
  Particle 	& $\pT$-cut 		& $\vert \eta \vert$-cut 	& $\Delta$R-cut 	\\
  \hline
  Jets 		& $>$ 30 $\GeV$ 	& $<$ 2.5			& $<$ 0.3		\\
  Muon		& $>$ 26 $\GeV$		& $<$ 2.1			& $<$ 0.3		\\
  Neutrino 	& $>$ 25 $\GeV$		& $<$ 2.5			& $<$ 0.3		
 \end{tabular}
\end{table}

%What is done and what is expected
The generated samples, each containing 20 000 events in order to be comparable in size to the data sample, are then analysed by the Matrix Element method and the correspondence between the obtained minimum and the coupling coefficient imposed during the generation process is determined. 
In the ideal case these two values should be identical, implying that both the model and the procedure developed to extract the estimator are behaving properly.
The outcome of the linearity test for this analysis is given in Figure~\ref{fig::CalibCurve}, which clearly indicates that the distribution of the minima can be described by a straight line with slope almost equal to $1$ ($a$ = 0.9713).
\\
%What is shown in the figure, and which range is important.
The fit on the distribution, the actual linearity test, has only been applied in the range $\left[-0.17, 0.17\right]$ since this is the relevant region to where the Standard Model configuration should be recovered. However, due to the precision of the obtained results, the region of interest can be limited further to values of $\vert \gR \vert$ smaller than 0.1, for which the linear behaviour is clearly visible.
\\
%Why deviation outside range!
The deviation from the expected distribution outside the considered range are most likely caused by the simplifications applied in the constructed model. In order to perfectly describe the physics processes over the entire $\gR$ range a more profound theoretical description of the Wtb interaction vertex is required, which lies beyond the scope of this thesis.
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/CalibrationCurve_SlopeComparision_DifferentCuts.pdf}
 \caption{Outcome of the linearity test for the created model, indicating the absence of a bias due to the assumed model approximations. The calibration is therefore described perfectly since it can be represented by a straight line with slope $1$.} \label{fig::CalibCurve}
\end{figure}
%********************************
%Question: Fit also done by excluding the outer bins?
%********************************
%

%Some conclusions
The performed linearity test has clearly indicated that both the model and method are behaving accordingly and that the obtained results are independent of the considered coupling coefficient.
Hence, no calibration is required to reinstore the expected linear behaviour of the Matrix Element method.
%The method can still be affected by a bias, but will be discussed in the next section since it should be determined using reconstructed events.
%An offset is still possible, but will be determined in the following section since the linearity test has been based purely on generator-level events.
%Any discrepancy caused by the use of reconstructed events will be investigated in the offset determination.


\subsection{Offset calibration}
\textit{Build up this subsection by first mentioning that there is a definite bias, but that a sophisticated method should be developed in order to reduce its influence.}
\\

Besides an almost perfect linear behaviour, the linearity test also indicated that no offset exists for generator-level events. This statement can not be generalised to reconstructed events since they can be influenced differently .... However simply applying the full analysis on the simulated collision events did not resulted in the expected outcome. On the contrary, the obtained Matrix Element method $-\ln(L_{MEM})$ distribution corresponded to a decreasing line such that the minimum is located at the edge of the considered range.
\\

The large contrast with the generator-level events seems to suggest that the Matrix Element method is not as efficient with reconstructed events as was the case for the generator events. This different behaviour is most likely caused by ...
\\

%The second characteristic to be discussed here focusses on the adaptations necessary to have the Matrix Element method correctly deal with reconstructed events. 
%The fact that these events are more prone to detector inefficiencies or misdetermined kinematics significantly complicates the calculations.

Another essential/vital feature that should be investigated thoroughly is the less optimal behaviour of the Matrix Element method when considering reconstructed collision events.
This because these type of events are more likely to be affected by detector inefficiencies, ill-defined kinematic variables and wrongly reconstructed event topologies.
%Analysing reconstructed collision events using a Matrix Element method deviates significantly from any generator-level study, mainly because the former type of events tend to be influenced by detector inefficiencies, ill-defined kinematic variables or wrongly reconstructed event topologies.
Since the Matrix Element method will treat all events as if they were real semi-leptonic top-quark pair decays, any inconsistency from the expected topology is likely to result in the underlying mathematical framework to misdetermine the event probability.
Therefore it is of crucial importance a procedure is developed in order to exclude the contribution of these sort of events, for which the details will be given in Section~\ref{subsec::EvtCleaning}.

\subsection{Matrix element event cleaning} \label{subsec::EvtCleaning}

A first glance at the measurement of the right-handed tensor coupling did not resulted in the expected outcome to be retrieved.
However, since the cross-section values have been determined with great care and moreover the linearity test has proven that both the developed model and method behave accordingly, this discrepancy is most probably caused by the/a different \textbf{nature/performance} of reconstructed events.
\\

A closer look at the issue seemed to indicate that the deviating effect originates from events badly handled by the Matrix Element method, an occurence that should be investigated in detail.
Before any action can be taken to limit the influence of these events, the main difference between generator-level and reconstructed events should completely be understood.
%
%Analysing reconstructed collision events using a Matrix Element method deviates significantly from any generator-level study, mainly because the former type of events tend to be influenced by detector inefficiencies, ill-defined kinematic variables or wrongly reconstructed event topologies. However, the Matrix Element method will treat all events as if they were real semi-leptonic top-quark pair decays, and any inconsistency from the expected topology is likely to result in the underlying mathematical framework to misdetermine the event probability.
%Therefore it is of crucial importance a procedure is developed in order to exclude the contribution of these sort of events, for which the details will be given in Section~\ref{subsec::EvtCleaning}.
%\\
%Unfortunately these type of events can become rather significant since on average they appear to get a lower value assigned than well-converging events. Since the event probability is converted into a $\chi^{2}_{MEM}$ or $-\ln(\mathcal{L}_{MEM})$, events with a lower value actually contribute the strongest to the overall result. Hence, special care should be awarded to these type of misidentified events and they should be excluded in order not to bias the outcome.
%The influence of these type of events can be seen from Figure~\ref{fig::SMLik}, which contains the $\chiSqMEM$ of the $\gR$ = $0.0$ configuration for each event. This distributions shows a clear tail which does not exist for generator-level events, given in the right-handed figure.

\paragraph{Characteristics of reconstructed events} \hfill \\ %Understanding the nature of the \textit{bad} events

The first measurement of the $\gR$ coefficient has been performed using reconstructed $\ttbar$ events for which the four jets have been correctly matched with the generator-level parton, in order to ensure the Standard Model configuration would be retrieved. This simulation sample should not be influenced by badly reconstructed event topologies and, especially due to the stringent event-selection applied, result in an almost impeccable agreement with the expectation.
\\
However, this was certainly not the case since the obtained $-\ln(\mathcal{L}_{MEM})$ distribution corresponded to a decreasing straight line such that the minimum was located at the edge of the considered range. This large discrepancy, in contradiction with the credibility established (on the model) by the linearity test, necessitated a thorough comparison of the (different) treatment of generator-level and reconstructed events by the Matrix Element method.
\\

In order to identify whether a specific type of events with a distinguishing signature is responsible for this \textbf{discrepancy}, an exhaustive study has been performed.
Numerous variables have been looked at in order to find any indication for the disagreement between the generator- and reconstructed-level measurement, and the most promising one appeared to be the value of the $\chiSqMEM$-distribution evaluated at the Standard Model configuration.
\\
This distribution has a significantly different shape for generator-level and reconstructed events, as can be seen in Figure~\ref{fig::SMLik}.
The latter one \textit{contains} a prominent(\textit{ly visible}) tail, which is on the other hand completely absent for the generator-level events.
%***************************
% Necessary to mention something about the different starting value??
%***************************
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLikelihoodValue_GenEventsSM.pdf} \hspace{0.3cm}
 %Taken from directory: Events_CalibCurve/CalibCurve_SemiMu_RgR_AllDeltaTF_MGSampleSM_20000Evts_CutsAlsoOnMET/SMLikelihoodValue_GenEventsSM.pdf
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLikelihoodValue_RecoEvents_MyTF.pdf}
 %--> Update this!!
 \caption{Distribution of the $\chi^{2}_{MEM}$-value for the $\gR$ = $0.0$ configuration for both the generator- (left) and reconstructed-level (right) events.} \label{fig::SMLik}
\end{figure}

Now that a variable has been discovered which is capable of identifying the events most likely responsible for the observed discrepancy, the origin of this phenomenon should be understood in detail.
\\
First of all, the same minimum-extraction procedure has been applied onto a sample containing simulated $\ttbar$ events for which at least one jet has not been matched with the correct generator-level parton.
This allowed to compare both the outcome and this $\chi^{2}_{MEM}$ distribution with the previously considered sample containing only correctly reconstructed $\ttbar$ events.
The obtained results were identical, the minimum was also here located at the edge of the considered range and the $\chiSqMEM$ distribution was characterised by exactly the same tail, as can be seen in Figure~\ref{fig::SMLikCorrVSWr}.
%In case the tail of this distribution would be influenced by badly reconstructed event topologies, this would become clearly visible from this comparison.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/ScaledContribution_CWU_LumiNorm.pdf}
 \caption{Distribution of the $\chi^{2}_{MEM}$-variable evaluated at the Standard Model configuration for correctly reconstructed (green) and wronly reconstructed $\ttbar$ events. Both distribution have been \textbf{scaled accordingly}. \textit{Should still remove data and unmatched!}} \label{fig::SMLikCorrVSWr}
\end{figure}
From this comparison can thus clearly be concluded that the incorrect determination of the event topology is not causing the peculiar behaviour of the Matrix Element method.
This was already expected, since otherwise the discrepancy would not have been observed for the sample containing only correctly reconstructed events.
\\
\\
Next it has been investigated how such a significant tail can arise and why the Matrix Element seems to be incapable of handling a specific type of reconstructed events.
One of the more obvious differences between generator-level and reconstructed events is the tendancy to be influenced by detector inefficiencies and ill-determined kinematic variables. For the reconstructed events this is a significant point of concern, amplified by the fact that the resolution functions of these events allow the kinematics to \textit{vary} in a much wider range.
\\
Due to the conversion from the MadWeight likelihood distribution $\mathcal{L}_{MEM}$ into a $\chi^{2}$ distribution, the events residing in the tail correspond to events with a on average lower event probability.
This seems to suggest that the Matrix Element method assigns events for which the underlying mathematical framework cannot converge a lower event probability, which should thus be excluded.

%*************************
% Decide: Interesting to keep this TF part???
%*************************
%Finally, the importance of the applied resolution function can be visualised in Figure~\ref{fig::SMLikTF} which shows this $\chiSqMEM$ variable in case the resolution function developed in Section~\ref{sec::TF} is considered and otherwise in case the basic Gaussian function is used to describe the smearing of the \textbf{what exactly?}.
%Comparing these two shows a clear dependence on this resolution function, again indicating that the events in the end of the tail cannot converge since the reconstructed kinematic information does not agree with the expectation within the range allowed by the resolution function.
%\\
%\begin{figure}[h!t]
% \centering
% \includegraphics[width = 0.35 \textwidth]{image.png} %Maybe show the two on top of each other? This way repeating the same figure can be avoided!!
% \caption{Distribution of the $\chi^{2}_{MEM}$-value for the $\gR$ = $0.0$ configuration for the resolution functions created specifically for this analysis (green) and for the basic Gaussian resolution %function of the Matrix Element method (blue).} \label{Fig::SMLikTF}
%\end{figure}

\paragraph{Developing the event-cleaning procedure} \hfill \\

Even though the process responsible for the deviating behaviour is not completely mastered, it seems more than plausible that the reconstructed events are heavily influenced by inefficiencies non-existing for generator-level events. Moreover, the Matrix Element method is developed to treat every event as if it is a perfectly described semileptonic top-quark pair decay. Any inconsistency from the expected topology is likely to result in the event probability being misdetermined since the mathematical framework of the method is unable to converge.
Nonetheless, it has been established that the origin of this abnormal behaviour is not caused by the applied event-selection procedure but is a \textbf{true} feature of the Matrix Element method such that a strategy should be developed to reduce the contribution of these type of events.
\\

This event-cleaning procedure should be created carefully since only the events residing in the tail should be excluded. It is not the goal of this additional event-selection requirement to distinguish between well and badly reconstructed events since this is taken care of by the event selection criteria formulated in Chapter~\ref{ch::EvtSel}.
Especially since the fraction of these latter type of events is small compared to the former type, as can be seen from Figure~\ref{fig::SMLikCorrVSWrUnSc}. This contains the same two distributions as shown in Figure~\ref{fig::SMLikCorrVSWr}, with the only difference that now they are drawn on scale.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/RelativeContribution_CWU_LumiNorm.pdf}
 \caption{Distribution of the $\chi^{2}_{MEM}$-variable evaluated at the Standard Model configuration for correctly reconstructed (green) and wronly reconstructed $\ttbar$ events drawn on scale. \textit{Should still remove data and unmatched!}} \label{fig::SMLikCorrVSWrUnSc}
\end{figure}

In this analysis it has been opted for to decide on the optimal cut-value using the full sample of semi-leptonic $\ttbar$ events and selecting the value for which no bias in the outcome is observed.
Hence, several cut-values have been applied onto this sample for which the corresponding minimum has been determined, as can be seen in Figure~\ref{fig::CutValueFit}.
The considered cut-values range between 60 and 70, and can thus all be found in the outer range of the $\chiSqMEM$ distribution.
\\
Figure~\ref{fig::CutValueFit} also indicates the strong dependence of the obtained minimum on the applied cut-value, implying that its optimal value should be determined with great care in order to avoid introducing a significant bias. It also confirms that only the events in the tail should be excluded since the events located more in the intermediate region of the $\chiSqMEM$ distribution, so between $60$ and $65$ approximately, still contain relevant information and should be preserved for further analysis.
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/LikCutFit_TTbarSemiLept_UpdatedXS.pdf}
 \caption{Minima obtained by applying different cut-values. This distribution has been fitted with a polynomial in order to determine the optimal cut-value, which correspond to the value for which no bias is recovered. \textit{Will highlight optimal point!}} \label{fig::CutValueFit}
\end{figure}

The overall distribution containing the minima corresponding to each cut-value is then fitted with a polynomial function, represented by the red curve in Figure~\ref{fig::CutValueFit}.
From this the optimal cut-value can easily be determined as being $63.92$ $\pm$ $xx?$ for which a minimum equal to $\gR$ = -0.001 $\pm$ 0.009 is recovered, which is clearly statistically compatible with 0.
The effect of this event-cleaning procedure on the different samples has been summarised in Table~\ref{table::CutInfl}, which varies significantly for the considered samples.
\\
\begin{table}[h!t]
 \centering
 \caption{Influence of the event-cleaning procedure on the different samples.} \label{table::CutInfl}
 \renewcommand{\arraystretch}{1.2}
 \begin{tabular}{c|c}
  Sample 		& Event reduction 	\\
  \hline
  $\ttbar$ (good)	& $\%$ 			\\
  $\ttbar$ (wrong) 	& $\%$ 			\\
 \end{tabular}
\end{table}

%Even with the knowledge that the method behaving as should be and that the cross-section normalisation is applying the correct factor, the results obtained from the Matrix Element method need to surpass an additional cleaning procedure. This is a quality inherent to the inprecise determination of both the event kinematics and the event topology when considering reconstructed events. Any deviation from the expected topology might result in the the calculation technique not converging and thus misdetermining the event probability.

Within the Matrix Element method events containing useful information are supposed to be characterised by a $\chiSqMEM$ curve ...\\
\textit{From the added 2D plots no real conclusion can be drawn unfortunately. The second derivative distribution was a possibility, but since it is just almost symmetric around zero it would only raise more questions when adding this distribution ...\\ So it seems that no actual explanation will be able to be given for this cut ...\\ Especially because the 2D plots which can be given indeed show that something goes wrong at the outer x-axis range but the behaviour at lower x-values is not as expected either ...}
\\
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/LnLikCut_ScatterPlot_SMLikvsMaxDelta_AllTT.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_ScdDerFine_CorrectTTbar.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_RightDeltaLnLik_CorrectTT.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/SMLik_vs_LeftDeltaLnLik_CorrectTT.pdf}
 \caption{2D plot for all $\ttbar$ events (so CWU combined -- scdDer only for correct ...). The two lower plots contain on the y-axis the $\chiSqMEM$ difference between $\gR$ = 0.0 and $\gR$ = $\pm$ 0.2. Hence in order to have minimum at zero, both should actually be negative!} \label{fig::SMLik2D}
\end{figure}

%\begin{figure}[h!t]
% \centering
% \includegraphics[width = 0.65 \textwidth]{Chapters/Chapter6_Analysis/Figures/Data_vs_SeparateTTbarJetsSemiLept_NotLumiScaled.pdf}
% \caption{} \label{fig::OptCutValue}
%\end{figure}


%--------------------------------------------------------------------------------------------------- \\
%Comparing the generator-level distribution with the one for the reconstructed events clearly shows that the events residing in the tail should be rejected. Considering different resolution functions has indicated that the shape and amplitude of the tail depends heavily on the applied resolution, indicating again that these type of events are less likely to be well reconstructed.
%Hence, the considered event-cleaning procedure will require the $\chi^{2}_{MEM}$ of each value to be lower than a specific cut-value. 
%\\
%
%The mentioned dependence on the resolution functions introduced for the reconstructed collision events can be visualised in Figure~\ref{fig::SMLikTF}, which contains this $\chiSqMEM$ variable at the $\gR$ = 0.0 point in case the resolution function developed in Section~\ref{sec::TF} is considered and in case a basic Gaussian function is used to describe the smearing of the \textbf{what exactly?}. 

\paragraph{Data-MC discrepancy}
Not a perfect agreement between data and MC (Yes, is within 1 sigma interval ...) AND should use the unweighted uncertainty for MC!:
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/CutValueFitted_DataVsAllMC.pdf}
 \caption{Minimum values obtained for the different cut-values considered for data (red) and all simulated (black) samples. Hence also the optimal cut-value differs slightly: 63.396 for data and 63.8764 for all simulated samples.}
\end{figure}

Shape is almost identical for the $\chi^{2}$ distribution evaluated at the Standard Model configuration.
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/StackedPlot_SMLikValue_AllMCAndData.pdf}
 \caption{Distribution of the $-\ln(\mathcal{L})$ distribution for data (red) and all simulated samples (black). This shows a nice agreement between the two.}
\end{figure}



\subsection{Statistical properties}
The developed technique to extract the relevant information from the Matrix Element method has proven to be uninfluenced by any bias, as has been shown in Section~\ref{sec::CalibCurve}.
Furthermore, the optimal cut-value for the event-cleaning procedure is chosen as such that the expected Standard Model value is recovered for the simulated signal events, top-quark pairs decay(ing semi-leptonical). Since the remaining simulation samples are all almost negligible compared to this one, the leading background contribution in this analysis is single-top production in the tW-channel which is about 50 times smaller, no significant influence on the overall outcome is expected from these types of events.
\\

However, additional research is still required in order to make sure the statistical properties of this analysis are well described.
This can be performed using a resampling technique which generates a set of samples by randomly selecting events from the considered simulated samples in accordance with a previously specified luminosity, in general the luminosity of the data sample.
This allows to obtain a representation of actual data and to verify whether the average result can be compared with expectation.
%Each of these generated samples is then treated as an actual data sample and the full analysis is applied in order to determine the distribution of both the 
\\
\\
Width of pull = 1.00395 $\pm$ 0.0240723 (using only ttbar semileptonic events)\\
Width of pull = 0.957432 $\pm$ 0.0238748 (using all ttbar events)\\
Width of pull = 0.987126 $\pm$ 0.0221517 (all MC)

\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/PseudoExp_MinimumDistr_AllTTbarSemiLept_UpdatedXS.pdf}
 \includegraphics[width = 0.45 \textwidth]{Chapters/Chapter6_Analysis/Figures/PseudoExp_UncDistr_AllTTbarSemiLept_UpdatedXS.pdf}
 \caption{Minimum and uncertainty distribution obtained for the 1000 considered pseudo experiments. (all semiLept TT)}  \label{fig::MinAndUnc}
\end{figure}

\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/PullDistr_AllTTbarSemiLept_UpdatedXS.pdf}
 \caption{Pull distribution} \label{fig::PullDistr}
\end{figure}

\section{Measurement of $\gR$ using the Matrix Element method} \label{sec::gRMeas}

\subsection{Data result}
\paragraph{MC results } \hfill \\

Nominal result is (Figure~\ref{fig::MinNominal}):
\begin{equation}
 \gR = -0.00139091 \pm 0.00912391
\end{equation}

\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/FittedGraph_NominalResult_TTbarJets.pdf}
 \caption{Obtained minimum distribution for the nominal case.} \label{fig::MinNominal}
\end{figure}

Separate events on the different background samples are not always perfectly described:
\begin{table}[h!t]
 \centering
 \caption{} \label{table::BckInfl}
 \renewcommand{\arraystretch}{1.2}
 \begin{tabular}{c|c}
  Sample 						& Minimum 			\\
  \hline
  semi-leptonic $\ttbar$ 				& -0.00142159 $\pm$ 0.00912416 	\\
  semi-leptonic $\ttbar$ + full-leptonic $\ttbar$ 	&  	\\
  semi-leptonic $\ttbar$ + W-jets (4j) 			&  	\\
  semi-leptonic $\ttbar$ + Z-jets (4j) 			&  		\\
  semi-leptonic $\ttbar$ + ST tChannel 			&  	\\
  semi-leptonic $\ttbar$ + ST tW-Channel  		&  	\\
  \hline
  Total MC 			& -0.000199381 $\pm$ 0.00888694 
 \end{tabular}
\end{table}

The curve obtained when considering all MC samples is given in Figure~\ref{fig::MinNominalAll}
\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/FittedGraph_NominalResult_AllMC.pdf}
 \caption{Obtained minimum distribution for the nominal case.} \label{fig::MinNominal}
\end{figure}

\paragraph{Actual Data result} \hfill \\

The obtained data-result is (shown in Figure~\ref{fig::MinData}):
\begin{equation}
 \gR = 0.00915763 \pm 0.00829786
\end{equation}

\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/FittedGraph_DataResult.pdf}
 \caption{Obtained minimum distribution for the data events.} \label{fig::MinData}
\end{figure}


\subsection{Systematic uncertainties}

Obtained distribution is not perfectly Gaussian, so herefore should be corrected for.
Hence an additional systematic will be introduced which takes into account the deviation from a Gaussian distribution.
\\

Result obtained for JESMinus is (Figure~\ref{fig::MinJESMinus}):
\begin{equation}
 \gR = 0.00376009 (\pm 0.00898 \qquad \textrm{using data-lumi})
\end{equation}

\begin{figure}[h!t]
 \centering
 \includegraphics[width = 0.7 \textwidth]{Chapters/Chapter6_Analysis/Figures/FittedGraph_JESMinusResult_TTbarJets.pdf}
 \caption{Obtained minimum distribution for the JES minus case.} \label{fig::MinJESMinus}
\end{figure}

